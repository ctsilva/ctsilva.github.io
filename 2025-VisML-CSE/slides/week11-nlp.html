<!DOCTYPE html>
<html lang="en"><head>
<script src="week11-nlp_files/libs/clipboard/clipboard.min.js"></script>
<script src="week11-nlp_files/libs/quarto-html/tabby.min.js"></script>
<script src="week11-nlp_files/libs/quarto-html/popper.min.js"></script>
<script src="week11-nlp_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="week11-nlp_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="week11-nlp_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="week11-nlp_files/libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.25">

  <meta name="author" content="Claudio Silva">
  <meta name="dcterms.date" content="2025-11-03">
  <title>Visualization for NLP and LLMs</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="week11-nlp_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="week11-nlp_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="week11-nlp_files/libs/revealjs/dist/theme/quarto-743137726eb562984e8d4ff610b648a8.css">
  <link rel="stylesheet" href="lab-light-theme.css">
  <link href="week11-nlp_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="week11-nlp_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="week11-nlp_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="week11-nlp_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section class="quarto-title-block center">
  <h1 class="title">Visualization for NLP and LLMs</h1>
  <p class="subtitle">CS-GY 9223 - Fall 2025</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Claudio Silva 
</div>
        <p class="quarto-title-affiliation">
            NYU Tandon School of Engineering
          </p>
    </div>
</div>

  <p class="date">2025-11-03</p>
</section>
<section>
<section class="title-slide slide level1 center">
<h1>NLP and Large Language Models</h1>

</section>
<section class="slide level2">
<h2>Today’s Agenda</h2>
<ol type="1">
<li><strong>NLP Fundamentals</strong>
<ul>
<li>Text processing pipeline</li>
<li>Traditional vs modern approaches</li>
</ul></li>
<li><strong>Visualizing Model Internals</strong>
<ul>
<li>RNN gradient flow</li>
<li>Hidden state analysis</li>
</ul></li>
<li><strong>Behavioral Analysis</strong>
<ul>
<li>Error discovery patterns</li>
<li>Counterfactual generation</li>
</ul></li>
<li><strong>LLM Visualization</strong>
<ul>
<li>Attention mechanisms</li>
<li>Prompt engineering tools</li>
</ul></li>
</ol>
<aside class="notes">
<p>Natural Language Processing has undergone a revolution with the advent of large language models. Today’s lecture bridges traditional NLP visualization techniques with modern LLM analysis methods. We’ll start with fundamental text processing concepts, then explore how visualization helps us understand both classical models like RNNs and modern transformer-based architectures. The transition from traditional NLP to LLMs represents not just a scale change but a fundamental shift in how we approach language understanding. Visualization plays a crucial role in making these black-box models more interpretable.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Visualization for NLP</h2>
<ul>
<li>NLP Basic</li>
<li><span style="color: grey;">Visualizing Traditional NLP Model’s Internal Structure</span></li>
<li><span style="color: grey;">Visualizing Traditional NLP Model’s Behavior</span></li>
<li><span style="color: grey;">Visualizing LLMs</span></li>
</ul>
</section>
<section class="slide level2">
<h2>NLP Basic: Text Processing Pipeline</h2>

<img data-src="figs/week11-nlp/slide1.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>The NLP pipeline begins with raw text and transforms it through multiple stages into a form suitable for machine learning. Tokenization splits text into units (words, subwords, or characters). Normalization handles case, punctuation, and special characters. Vectorization converts tokens to numbers - from simple one-hot encoding to sophisticated contextual embeddings. Each stage involves design decisions that significantly impact downstream performance. For example, aggressive normalization might remove important signals (like capitalization indicating proper nouns), while preserving too much variation increases vocabulary size and sparsity.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>NLP Basic: Word Embeddings</h2>

<img data-src="figs/week11-nlp/slide2.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Word embeddings revolutionized NLP by providing dense, continuous representations where similar words have similar vectors. The key insight is the distributional hypothesis: words appearing in similar contexts have similar meanings. Word2Vec uses shallow neural networks to predict context words (CBOW) or target words (Skip-gram). GloVe combines global matrix factorization with local context windows. FastText extends Word2Vec by using character n-grams, helping with out-of-vocabulary words. These embeddings capture surprising regularities - the famous “king - man + woman = queen” demonstrates that vector arithmetic can encode analogical reasoning.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>NLP Basic: Sequence Models</h2>

<img data-src="figs/week11-nlp/slide3.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Sequence modeling is central to NLP because language is inherently sequential. RNNs maintain a hidden state that gets updated at each time step, theoretically capturing all previous context. However, standard RNNs suffer from vanishing gradients, making it hard to learn long-range dependencies. LSTMs and GRUs address this with gating mechanisms that control information flow. Bidirectional RNNs process sequences in both directions, capturing both past and future context. The sequential nature of RNNs makes them slow to train and inference, motivating the development of parallelizable architectures like Transformers.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>NLP Basic: Text Preprocessing</h2>

<img data-src="figs/week11-nlp/slide4.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Text preprocessing is crucial but often underappreciated. Common steps include lowercasing (but this loses information like proper nouns), removing stop words (but they’re important for understanding negation and questions), stemming/lemmatization (reducing words to root forms), and handling special tokens like URLs, numbers, and emojis. Modern deep learning approaches often use minimal preprocessing, letting the model learn what’s important. However, careful preprocessing can significantly reduce vocabulary size and improve generalization, especially with limited training data. The key is understanding your task - sentiment analysis might benefit from preserving emoticons, while topic modeling might safely remove them.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>NLP Basic: Feature Extraction</h2>

<img data-src="figs/week11-nlp/slide5.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Feature extraction transforms text into numerical features for machine learning. Traditional approaches include bag-of-words (word counts), TF-IDF (term frequency-inverse document frequency), and n-grams (sequences of n words). These create sparse, high-dimensional representations. Modern approaches learn dense features: word embeddings, sentence encoders, and contextual representations from transformers. The choice depends on your task and data. Sparse features work well for many classification tasks with limited data, while dense representations excel at capturing semantic similarity and transfer learning. Visualization plays a key role in understanding what features your model learns and relies upon.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>NLP Basic: Language Model Architectures</h2>

<img data-src="figs/week11-nlp/slide6.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Language model architectures have evolved from simple n-gram models to sophisticated neural architectures. N-gram models estimate probabilities based on local context but suffer from data sparsity. RNN language models maintain hidden states to capture longer context but process sequentially. Transformer-based models like GPT and BERT use self-attention to model global dependencies efficiently. The key innovation is attention mechanisms that allow models to focus on relevant parts of the input. Pre-trained language models have become the foundation of modern NLP, providing rich representations that transfer across tasks. Understanding these architectures helps in choosing the right model and visualization technique for your application.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>NLP Tasks Taxonomy</h2>
<aside class="notes">
<p>NLP tasks span from low-level syntactic analysis to high-level semantic understanding and generation. Token-level tasks like POS tagging and NER identify properties of individual words. Sequence-level tasks like machine translation and summarization transform entire texts. Classification tasks like sentiment analysis and topic modeling categorize documents. Generation tasks create new text. This taxonomy matters for visualization because different tasks benefit from different visual representations. Token-level tasks use attention heatmaps and dependency graphs. Document-level tasks use embedding projections and clustering visualizations. Understanding task requirements helps select appropriate models and interpretability methods.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="columns">
<div class="column" style="width:50%;">
<h3>Token &amp; Syntax Level</h3>
<ul>
<li>Named entity recognition</li>
<li>Parts-of-speech tagging</li>
<li>Dependency parsing</li>
<li>Grammatical error correction</li>
<li>Word sense disambiguation</li>
<li>Coreference resolution</li>
</ul>
</div><div class="column" style="width:50%;">
<h3>Document &amp; Semantic Level</h3>
<ul>
<li>Text summarization</li>
<li>Question answering</li>
<li>Machine translation</li>
<li>Sentiment analysis</li>
<li>Topic modeling</li>
<li>Dialogue systems</li>
</ul>
</div></div>
</section>
<section class="slide level2">
<h2>Visualization for NLP</h2>
<ul>
<li><span style="color: grey;">NLP Basic</span></li>
<li>Visualizing Traditional NLP Model’s Internal Structure</li>
<li>Visualizing Traditional NLP Model’s Behavior</li>
<li>Visualizing LLMs</li>
</ul>
</section>
<section class="slide level2">
<h2>Visualization for NLP</h2>
<ul>
<li><span style="color: grey;">NLP Basic</span></li>
<li>Visualizing Traditional NLP Model’s Internal Structure</li>
<li><span style="color: grey;">Visualizing Traditional NLP Model’s Behavior</span></li>
<li><span style="color: grey;">Visualizing LLMs</span></li>
</ul>
</section>
<section class="slide level2">
<h2>RNNbow: Visualizing Gradient Flow</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3>Key Innovation</h3>
<ul>
<li>Visualizes backpropagation gradients in RNNs</li>
<li>Reveals vanishing/exploding gradient problems</li>
<li>Tracks learning dynamics across epochs</li>
</ul>
<h3>Applications</h3>
<ul>
<li>Model debugging</li>
<li>Architecture comparison</li>
<li>Training optimization</li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="figs/week11-nlp/paper17-1.png"></p>
</div></div>
<div class="footer">
<p>Cashman et al.&nbsp;(2018). <a href="https://doi.org/10.1109/MCG.2018.042731661">RNNbow: Visualizing Learning Via Backpropagation Gradients in RNNs</a>. IEEE CG&amp;A.</p>
</div>
<aside class="notes">
<p>RNNbow addresses a fundamental challenge in training recurrent networks: understanding gradient flow through time. The visualization reveals how gradients propagate backwards through the network, exposing the vanishing gradient problem that plagued early RNNs. This tool was instrumental in motivating architectural innovations like LSTMs and GRUs. The ability to compare gradients across different training epochs provides insights into learning dynamics that are impossible to obtain from scalar metrics alone.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>RNN Architecture Visualization</h2>

<img data-src="figs/week11-nlp/paper17-2.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>This visualization shows how RNNs process sequences by maintaining and updating hidden states over time. Each node represents a hidden state vector, and edges show the flow of information. The recurrent connections (horizontal arrows) carry information from previous time steps, while vertical connections show input/output flow. Color coding often represents activation magnitudes or gradient values. This unrolled view makes clear why RNNs struggle with long sequences - information must pass through many nonlinear transformations, leading to signal degradation. Understanding this architecture is crucial for interpreting gradient flow visualizations and diagnosing training problems.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Gradient Flow Analysis</h2>

<img data-src="figs/week11-nlp/paper17-3.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Gradient flow visualization is essential for understanding RNN training dynamics. This diagram traces how gradients propagate backward through time during backpropagation. Line thickness or color intensity represents gradient magnitude. The vanishing gradient problem becomes visually apparent - gradients exponentially decay as they flow backward, making it impossible to learn long-range dependencies. This visualization technique has been instrumental in motivating architectural improvements. LSTMs and GRUs include “gradient highways” - paths where gradients can flow with minimal attenuation. Gradient clipping and careful initialization also help, but the fundamental sequential bottleneck remains.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Training Dynamics: Epoch Comparison</h2>
<div class="columns">
<div class="column" style="width:45%;">
<h3>Gradient Evolution</h3>
<ul>
<li>Early epochs: chaotic gradients</li>
<li>Middle epochs: pattern emergence</li>
<li>Late epochs: stable flow</li>
<li>Convergence indicators</li>
</ul>
</div><div class="column" style="width:55%;">
<p><img data-src="figs/week11-nlp/paper17-4.png"></p>
</div></div>
<aside class="notes">
<p>Comparing gradient flow across training epochs reveals how RNNs learn. Early in training, gradients are chaotic and unstable, reflecting the random initial weights. As training progresses, gradient patterns stabilize and become more structured. Successful training shows gradients maintaining reasonable magnitudes throughout the sequence. Failed training often shows gradients vanishing (approaching zero) or exploding (growing exponentially). This visualization helps identify when to stop training, adjust learning rates, or modify architectures. It also reveals which parts of the sequence contribute most to learning - often later time steps dominate due to shorter gradient paths.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: RNN</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Comparing gradients at different epochs of training:</p>
</div><div class="column" style="width:70%;">
<p><img data-src="figs/week11-nlp/paper17-6.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: RNN</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Exploring vanishing gradient</p>
</div><div class="column" style="width:70%;">
<p><img data-src="figs/week11-nlp/paper17-5.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: RNN</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Poorly Learning C</p>
</div><div class="column" style="width:70%;">
<p><img data-src="figs/week11-nlp/paper17-5.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>LSTMVis: Understanding Hidden States</h2>

<img data-src="figs/week11-nlp/paper13.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Strobelt et al.&nbsp;(2017). <a href="https://doi.org/10.1109/TVCG.2017.2744158">LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in RNNs</a>. IEEE TVCG.</p>
</div>
<aside class="notes">
<p>LSTMVis pioneered the visual analysis of RNN hidden states, revealing how these models encode linguistic information. The tool allows users to select phrases and see which hidden units activate, discovering that different units specialize in different linguistic phenomena. This work demonstrated that RNNs learn interpretable representations despite not being explicitly trained to do so.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Hidden values in LSTM/RNN</p>
</div><div class="column" style="width:70%;">
<p><img data-src="figs/week11-nlp/paper13-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Hidden States Sequence of high-dimensional vectors. What are some options for visualization?</p>
</div><div class="column" style="width:70%;">
<p><img data-src="figs/week11-nlp/paper18-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Hidden States Sequence of high-dimensional vectors. What are some options for visualization?</p>
</div><div class="column" style="width:70%;">
<p><img data-src="figs/week11-nlp/paper18-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Hidden States Sequence of high-dimensional vectors. What are some options for visualization?</p>
</div><div class="column" style="width:70%;">
<p><img data-src="figs/week11-nlp/paper13-5.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>User selects sequences. Configurable threshold: all hidden states in the selected sequence must exceed threshold</p>
</div><div class="column" style="width:70%;">
<p><img data-src="figs/week11-nlp/paper18-3.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>User selects sequences. Configurable threshold: all hidden states in the selected sequence must exceed threshold</p>
</div><div class="column" style="width:70%;">
<p><img data-src="figs/week11-nlp/paper13-6.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Collection-Level Hidden State Analysis</h2>
<div class="columns">
<div class="column" style="width:30%;">
<h3>Visualization Challenges</h3>
<ul>
<li>High dimensionality</li>
<li>Temporal dynamics</li>
<li>Multiple sequences</li>
<li>Pattern discovery</li>
</ul>
</div><div class="column" style="width:70%;">
<p><img data-src="figs/week11-nlp/paper13-1.png"></p>
</div></div>
<aside class="notes">
<p>Visualizing hidden states across an entire dataset presents unique challenges. We need to understand patterns across three dimensions: hidden units, time steps, and different input sequences. Dimensionality reduction techniques like PCA or t-SNE can reveal clusters of similar hidden states, suggesting that the model groups similar inputs. Trajectory visualizations show how hidden states evolve over time for different input types. Statistical aggregations reveal which units are most active and when. This collection-level view helps identify model capacity issues (are all units being used?), specialization patterns (do units have consistent roles?), and dataset biases (do certain inputs always produce similar hidden states?).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Visualization for NLP</h2>
<ul>
<li><span style="color: grey;">NLP Basic</span></li>
<li><span style="color: grey;">Visualizing Traditional NLP Model’s Internal Structure</span></li>
<li>Visualizing Traditional NLP Model’s Behavior</li>
<li><span style="color: grey;">Visualizing LLMs</span></li>
</ul>
</section>
<section class="slide level2">
<h2>iSea: Semantic Error Analysis</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/week11-nlp/paper19-3.png" class="quarto-figure quarto-figure-center" height="600"></p>
</figure>
</div>
<div style="text-align: center; font-size: 1.2em;">
<p><strong>Overall Accuracy: 80%</strong> - But where are the failures?</p>
</div>
<div class="footer">
<p>Wu et al.&nbsp;(2019). <a href="https://doi.org/10.1145/3290605.3300343">iSea: Interactive Semantic Error Analysis</a>. CHI 2019.</p>
</div>
<aside class="notes">
<p>A model with 80% accuracy might seem good, but understanding the 20% of failures is crucial for improvement. iSea moves beyond aggregate metrics to identify systematic error patterns. Rather than looking at random failures, it discovers semantically coherent subpopulations where the model consistently fails. This approach has revealed biases, dataset artifacts, and fundamental model limitations that would be invisible in traditional evaluation.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>

<img data-src="figs/week11-nlp/paper19-3.png" class="r-stretch"><p>Where does the model make mistakes?</p>
<p>Why does the model make these mistakes?</p>
<p>How can we improve the model performance?</p>
<p>…</p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Subpopulation-Level Error Analysis is Common for NLP Models <img data-src="figs/week11-nlp/paper19-4.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Subpopulation-Level Error Analysis is Common for NLP Models <img data-src="figs/week11-nlp/paper19-4.png"></p>
<p>Not able to capture the errors grounded in specific semantic concepts.</p>
<p>Requires prior knowledge to construct subpopulations.</p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>

<img data-src="figs/week11-nlp/paper19-1.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>

<img data-src="figs/week11-nlp/paper19-5.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Features to Describe A Subpopulation</p>
<ul>
<li>Token
<ul>
<li>e.g., all the documents that contain “delicious”.</li>
</ul></li>
<li>Concept
<ul>
<li>e.g., all the documents that contain “delicious”/“tasty”/”yummy”/…</li>
</ul></li>
<li>High-level Features
<ul>
<li>e.g., all the documents that contain a high percentage of adjectives.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>To describe error-prone subpopulations, we use a set of if-then rules. <img data-src="figs/week11-nlp/paper19-6.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Through iterative design process, we identified four principles of presenting the error rules:</p>
<ul>
<li>Principle 1: Limit the number of conditions.
<ul>
<li>To keep the rule interpretable.</li>
</ul></li>
<li>Principle 2: Test significance.
<ul>
<li>To ensure the high error rate in the subpopulation does not occur by chance</li>
</ul></li>
<li>Principle 3: Limit the cardinality of features.
<ul>
<li>Use low/medium/high instead of actual values (e.g., &gt;20, &lt;30) to keep it interpretable.</li>
</ul></li>
<li>Principle 4: Avoid negation for tokens.
<ul>
<li>To ensure actionable insights.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Automatic Error Discovery <img data-src="figs/week11-nlp/paper19-8.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Automatic Error Discovery <img data-src="figs/week11-nlp/paper19-9.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Automatic Error Discovery <img data-src="figs/week11-nlp/paper19-10.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Views to Support Learning <img data-src="figs/week11-nlp/paper19-7.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Validating <img data-src="figs/week11-nlp/paper19-11.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Validating <img data-src="figs/week11-nlp/paper19-12.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Validating <img data-src="figs/week11-nlp/paper19-13.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Interpret Errors Causes <img data-src="figs/week11-nlp/paper19-14.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Hypothesis Testing <img data-src="figs/week11-nlp/paper19-15.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Rule Editing &amp; Concept Construction <img data-src="figs/week11-nlp/paper19-16.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>

<img data-src="figs/week11-nlp/paper19-2.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Polyjuice: Counterfactual Generation</h2>
<div class="columns">
<div class="column" style="width:35%;">
<h3>Key Features</h3>
<ul>
<li>Generates diverse counterfactuals</li>
<li>Controls perturbation types</li>
<li>Reveals model robustness issues</li>
</ul>
<h3>Applications</h3>
<ul>
<li>Data augmentation</li>
<li>Robustness testing</li>
<li>Bias detection</li>
</ul>
</div><div class="column" style="width:65%;">
<p><img data-src="figs/week11-nlp/paper20-1.png"></p>
</div></div>
<div class="footer">
<p>Wu et al.&nbsp;(2021). <a href="https://doi.org/10.18653/v1/2021.acl-long.523">Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models</a>. ACL 2021.</p>
</div>
<aside class="notes">
<p>Polyjuice addresses a critical challenge in NLP model evaluation: understanding robustness to input variations. By generating controlled counterfactuals, it reveals whether models rely on spurious correlations or genuine understanding. This tool has been instrumental in discovering dataset biases and improving model robustness through targeted data augmentation.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: Polyjuice</h2>

<img data-src="figs/week11-nlp/paper20-2.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualization for NLP</h2>
<ul>
<li><span style="color: grey;">NLP Basic</span></li>
<li><span style="color: grey;">Visualizing Traditional NLP Model’s Internal Structure</span></li>
<li><span style="color: grey;">Visualizing Traditional NLP Model’s Behavior</span></li>
<li>Visualizing LLMs</li>
</ul>
</section>
<section class="slide level2">
<h2>Attention Visualization in Transformers</h2>

<img data-src="figs/week11-nlp/paper1.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Vig (2019). <a href="https://doi.org/10.18653/v1/P19-3007">A Multiscale Visualization of Attention in the Transformer Model</a>. ACL 2019.</p>
</div>
<aside class="notes">
<p>Attention mechanisms are the core of modern LLMs, but understanding what models “attend to” is challenging. This visualization reveals how different attention heads specialize in different linguistic phenomena: some track syntax, others capture semantic relationships, and some focus on positional patterns. The multi-scale approach allows exploration from individual token relationships to aggregate patterns across layers.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>LLM Architecture: Self-Attention</h2>

<img data-src="figs/week11-nlp/paper2.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Self-attention is the core mechanism that enables transformers to model long-range dependencies efficiently. Unlike RNNs that process sequentially, attention computes relationships between all pairs of positions simultaneously. The attention matrix shows which tokens the model “looks at” when processing each token. Multiple attention heads learn different relationship types - some track syntax (subject-verb agreement), others capture semantic relationships (coreference), and some focus on position (attending to adjacent tokens). Visualizing attention patterns helps understand model decisions and identify potential biases or failure modes. However, attention doesn’t always equal explanation - high attention doesn’t necessarily mean high importance for the final prediction.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Multi-Head Attention Patterns</h2>
<div class="columns">
<div class="column" style="width:70%;">
<p><img data-src="figs/week11-nlp/paper3-1.png"></p>
</div><div class="column" style="width:30%;">
<p><img data-src="figs/week11-nlp/paper3-2.png"> <img data-src="figs/week11-nlp/paper3-3.png"></p>
</div></div>
<aside class="notes">
<p>Transformers use multiple attention heads that learn to focus on different types of information. This visualization shows how different heads specialize: some become “positional” heads attending to nearby tokens, others are “syntactic” heads tracking grammatical dependencies, and some are “semantic” heads linking related concepts. The multi-head design provides redundancy and allows the model to simultaneously attend to information at different positions and representation subspaces. Analyzing head specialization helps understand model capabilities and can guide model pruning - some heads can be removed with minimal performance impact. This visualization technique has revealed that many heads in large models are redundant or inactive.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>

<img data-src="figs/week11-nlp/paper4.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>

<img data-src="figs/week11-nlp/paper5.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:40%;">
<p><img data-src="figs/week11-nlp/paper6-1.png"></p>
</div><div class="column" style="width:60%;">
<p><img data-src="figs/week11-nlp/paper6-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/week11-nlp/paper7-1.png"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="figs/week11-nlp/paper7-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>

<img data-src="figs/week11-nlp/paper8.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>

<img data-src="figs/week11-nlp/paper9.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:55%;">
<p><img data-src="figs/week11-nlp/paper10-1.png"></p>
</div><div class="column" style="width:45%;">
<p><img data-src="figs/week11-nlp/paper10-2.png"> <img data-src="figs/week11-nlp/paper10-3.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:35%;">
<p><img data-src="figs/week11-nlp/paper11-1.png"></p>
</div><div class="column" style="width:40%;">
<p><img data-src="figs/week11-nlp/paper11-2.png"></p>
</div><div class="column" style="width:25%;">
<p><img data-src="figs/week11-nlp/paper11-3.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:55%;">
<p><img data-src="figs/week11-nlp/paper12-1.png"></p>
</div><div class="column" style="width:45%;">
<p><img data-src="figs/week11-nlp/paper12-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>

<img data-src="figs/week11-nlp/paper14.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:55%;">
<p><img data-src="figs/week11-nlp/paper15-1.png"></p>
</div><div class="column" style="width:45%;">
<p><img data-src="figs/week11-nlp/paper15-2.png"> <img data-src="figs/week11-nlp/paper15-3.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="figs/week11-nlp/paper16-1.png"></p>
</div><div class="column" style="width:55%;">
<p><img data-src="figs/week11-nlp/paper16-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>POEM: Prompt Engineering for Multimodal LLMs</h2>

<img data-src="figs/week11-nlp/paper21-1.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Guan et al.&nbsp;(2024). <a href="https://arxiv.org/abs/2406.03843">POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning</a>. arXiv preprint.</p>
</div>
<aside class="notes">
<p>POEM represents the frontier of LLM interaction design, addressing the challenge of prompt engineering for multimodal models. As LLMs become capable of processing images, video, and text together, understanding how to craft effective prompts becomes increasingly complex. POEM provides visual feedback on prompt effectiveness, suggests improvements, and helps users understand the model’s reasoning process across modalities. This is particularly important as prompt engineering has become a critical skill for effectively using LLMs.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<p>Multi-Modal Interaction <img data-src="figs/week11-nlp/paper21-3.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<p>POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/week11-nlp/paper21-2.png"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="figs/week11-nlp/paper21-4.png"></p>
</div></div>

</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="figs/vida.jpg" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://engineering.nyu.edu" class="uri">https://engineering.nyu.edu</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="week11-nlp_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="week11-nlp_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="week11-nlp_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="week11-nlp_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="week11-nlp_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="week11-nlp_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="week11-nlp_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="week11-nlp_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="week11-nlp_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="week11-nlp_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'fast',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>