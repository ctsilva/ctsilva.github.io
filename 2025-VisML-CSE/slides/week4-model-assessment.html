<!DOCTYPE html>
<html lang="en"><head>
<script src="week4-model-assessment_files/libs/clipboard/clipboard.min.js"></script>
<script src="week4-model-assessment_files/libs/quarto-html/tabby.min.js"></script>
<script src="week4-model-assessment_files/libs/quarto-html/popper.min.js"></script>
<script src="week4-model-assessment_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="week4-model-assessment_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="week4-model-assessment_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="week4-model-assessment_files/libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="week4-model-assessment_files/libs/quarto-contrib/videojs/video.min.js"></script>
<link href="week4-model-assessment_files/libs/quarto-contrib/videojs/video-js.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.24">

  <meta name="author" content="Claudio Silva">
  <meta name="dcterms.date" content="2025-09-22">
  <title>Model Assessment and Evaluation</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="week4-model-assessment_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="week4-model-assessment_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="week4-model-assessment_files/libs/revealjs/dist/theme/quarto-743137726eb562984e8d4ff610b648a8.css">
  <link rel="stylesheet" href="lab-light-theme.css">
  <link href="week4-model-assessment_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="week4-model-assessment_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="week4-model-assessment_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="week4-model-assessment_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section class="quarto-title-block center">
  <h1 class="title">Model Assessment and Evaluation</h1>
  <p class="subtitle">CS-GY 9223 - Fall 2025</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Claudio Silva 
</div>
        <p class="quarto-title-affiliation">
            NYU Tandon School of Engineering
          </p>
    </div>
</div>

  <p class="date">2025-09-22</p>
</section>
<section>
<section class="title-slide slide level1 center">
<h1>Model Assessment</h1>

</section>
<section class="slide level2">
<h2>Agenda</h2>
<p><br>
</p>
<ol type="1">
<li><p>Confusion Matrices and ROC Curves</p></li>
<li><p>Visual Analytics Systems for Model Performance</p></li>
<li><p>Calibration</p></li>
</ol>
<aside class="notes">
<p>Today we’re going to talk about model assessment and evaluation. We’ll start with some of the most common tools: confusion matrices and ROC curves. Then we’ll look at some more advanced visual analytics systems for evaluating model performance. Finally, we’ll do a deep dive into the concept of calibration, which is becoming increasingly important in modern machine learning.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section class="title-slide slide level1 center">
<h1>Confusion Matrices, ROC Curves</h1>

</section>
<section class="slide level2">
<h2>Scenario: Disease Prediction</h2>
<ul>
<li><p>Consider a disease prediction model. Suppose the hypothetical disease has a 5% prevalence in the population</p></li>
<li><p>The given model converges on the solution of predicting that nobody has the disease (i.e., the model predicts “0” for every observation)</p></li>
<li><p>Our model is 95% accurate</p></li>
<li><p>Yet, public health officials are stumped</p></li>
</ul>
<aside class="notes">
<p>This scenario illustrates a common problem with using a single metric like accuracy to evaluate a model, especially with imbalanced datasets. A model can achieve high accuracy by simply predicting the majority class, but it will be useless in practice. This is why we need more sophisticated evaluation methods.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Scenario: Handwritten Digits</h2>
<ul>
<li><p>Consider a model to identify handwritten digits. All digits are equally probable and equally represented in the training and test datasets.</p></li>
<li><p>The model correctly identifies all of the digits, except for digit <span class="math inline">\(5\)</span>, classifying half of the <span class="math inline">\(5\)</span>s samples as <span class="math inline">\(6\)</span> and the other half is correctly identified</p></li>
<li><p>The accuracy of this model is <span class="math inline">\(95\%\)</span>. Is this information enough to determine whether the model is good or not?</p></li>
</ul>
<aside class="notes">
<p>This is another example of how accuracy can be misleading. The model is 95% accurate, but it has a specific, systematic error: it confuses the digit 5 with 6. A single accuracy number hides this important information. We need tools that can show us <em>what</em> kinds of errors the model is making.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>

<img data-src="figs/model_assessment_figs/MNIST.webp" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>This slide shows examples of handwritten digits from the MNIST dataset, which is a widely used benchmark for image classification models. As we just discussed, even with a high accuracy of 95%, there can be underlying issues with how specific digits are classified.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Extended Confusion Matrix</h2>

<img data-src="figs/model_assessment_figs/extended_confusion_matrix.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Here is a more detailed view of a confusion matrix. It shows the number of true positives, true negatives, false positives, and false negatives. From these four numbers, we can calculate many other metrics, such as precision, recall, and F1-score. It also shows the per-class precision and recall.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Confusion Matrices: A Deeper Look</h2>
<div class="columns">
<div class="column">
<p><img data-src="figs/model_assessment_figs/sphx_glr_plot_label_propagation_digits_001.png"></p>
</div><div class="column">
<p><strong>Pros</strong></p>
<ul>
<li><strong>Intuitive:</strong> Easy to understand the concept of correct and incorrect classifications.</li>
<li><strong>Standardized Metrics:</strong> Forms the basis for many standard evaluation metrics like precision, recall, and F1-score.</li>
<li><strong>Error Analysis:</strong> Helps to identify which classes are being confused with each other.</li>
</ul>
<p><strong>Cons</strong></p>
<ul>
<li><strong>Scalability:</strong> Can be hard to visualize and interpret for a large number of classes. The matrix becomes a large, dense grid.</li>
<li><strong>Probabilistic Output:</strong> Doesn’t directly show the model’s confidence in its predictions. A prediction that was ‘barely wrong’ is treated the same as one that was ‘very wrong’.</li>
<li><strong>Instance-level Detail:</strong> Hides instance-level details. You can’t see individual errors.</li>
<li><strong>The “Squares” paper by Ren et al.&nbsp;(2016) points out that confusion matrices can obscure important patterns in model behavior and make it hard to prioritize what to fix.</strong></li>
</ul>
</div></div>
<aside class="notes">
<p>This slide summarizes the pros and cons of using confusion matrices. While they are intuitive and provide the basis for many metrics, they have limitations in terms of scalability and the insights they provide for probabilistic outputs. The ‘Squares’ paper, which we will discuss later, addresses some of these limitations.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Confusion Matrices in sklearn</h2>
<div id="9d3233b4" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href=""></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span>
<span id="cb1-2"><a href=""></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-3"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-4"><a href=""></a></span>
<span id="cb1-5"><a href=""></a>X,y <span class="op">=</span> datasets.make_classification(<span class="dv">5000</span>, <span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb1-6"><a href=""></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb1-7"><a href=""></a>clf <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span><span class="dv">0</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="232aee50" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href=""></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-2"><a href=""></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb2-3"><a href=""></a></span>
<span id="cb2-4"><a href=""></a>clf.fit(X_train, y_train)</span>
<span id="cb2-5"><a href=""></a></span>
<span id="cb2-6"><a href=""></a>ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, cmap<span class="op">=</span>plt.cm.Blues)</span>
<span id="cb2-7"><a href=""></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="week4-model-assessment_files/figure-revealjs/cell-3-output-1.png" width="515" height="429"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>Here we see how to generate a confusion matrix using the scikit-learn library in Python. The code is straightforward. We first define and split the data, then we fit a logistic regression classifier. The <code>ConfusionMatrixDisplay</code> function then takes the classifier and the test data as input to plot the matrix.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Confusion Matrices</h2>
<div class="columns">
<div class="column">
<p><img data-src="figs/model_assessment_figs/sphx_glr_plot_label_propagation_digits_001.png"></p>
</div><div class="column">
<div class="fragment">
<p><strong>Pros</strong></p>
<ul>
<li>Many derived metrics<br>
</li>
<li>Easy to implement<br>
</li>
<li>Summary of model mistakes is clear</li>
</ul>
</div>
<div class="fragment">
<p><strong>Cons</strong></p>
<ul>
<li>Hard to scale<br>
</li>
<li>Hard to assess probabilistic output<br>
</li>
<li>Hard to view individual errors</li>
</ul>
</div>
</div></div>
<aside class="notes">
<p>To reiterate, confusion matrices are a fundamental tool. They offer a quick summary of a model’s performance and are easy to implement. However, as the number of classes grows, they become difficult to interpret. They also don’t capture the full picture of probabilistic classifiers and hide instance-level errors.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Neo: Hierarchical Confusion Matrix</h2>
<iframe data-external="1" src="https://www.youtube.com/embed/8ZxvsLPIF_Q" width="80%" height="80%" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<aside class="notes">
<p>Neo is a research project that introduces a hierarchical confusion matrix. This is particularly useful when you have a large number of classes that have a natural hierarchy. For example, if you are classifying animals, you might have a hierarchy of mammals, birds, reptiles, etc. A hierarchical confusion matrix can help you see if your model is making errors at a high level (e.g., confusing a mammal for a bird) or at a low level (e.g., confusing a cat for a dog).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Receiver Operating Characteristic (ROC)</h2>
<div class="columns">
<div class="column" style="width:60%;">
<ul>
<li><p>ROC analysis is another way to assess a classifier’s output</p></li>
<li><p>ROC analysis developed out of radar operation in the second World War, where operators were interested in detecting signal (enemy aircraft) versus noise</p></li>
<li><p>We create an ROC curve by plotting the true positive rate (TPR) against the false positive rate (FPR) at various thresholds</p>
<ul>
<li><p><strong>True Positive Rate (TPR)</strong>, also known as Recall or Sensitivity, is the proportion of actual positives that are correctly identified as such (TP / (TP + FN)).</p></li>
<li><p><strong>False Positive Rate (FPR)</strong> is the proportion of actual negatives that are incorrectly identified as positive (FP / (FP + TN)).</p></li>
</ul></li>
</ul>
</div><div class="column" style="width:35%;">
<p><img data-src="figs/model_assessment_figs/roc_data_aircraft.png"></p>
</div></div>
<aside class="notes">
<p>We are now moving on to another important tool for model evaluation: the Receiver Operating Characteristic, or ROC curve. The concept of ROC analysis has its roots in signal detection theory, and it has been widely adopted in machine learning. It provides a way to visualize the performance of a classifier at all classification thresholds.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>ROC Curve</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p><img data-src="figs/model_assessment_figs/intro_roc.png"></p>
<div class="fragment">
<p><img data-src="figs/model_assessment_figs/confusion_matrix_roc.png"></p>
</div>
</div><div class="column" style="width:40%;">
<div class="fragment">
<p><img data-src="figs/model_assessment_figs/discrete_roc_graph.png"></p>
</div>
</div></div>
<aside class="notes">
<p>An ROC curve shows the trade-off between the true positive rate and the false positive rate for a binary classifier as the discrimination threshold is varied. The top-left corner of the plot is the ideal point - a false positive rate of 0, and a true positive rate of 1. This is not always possible in practice, but it is the goal.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>ROC Curve</h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="figs/model_assessment_figs/roc_curve_left.png"></p>
</div><div class="column" style="width:55%;">
<p><img data-src="figs/model_assessment_figs/roc_curve_right.png"></p>
</div></div>
<aside class="notes">
<p>Here we see how the ROC curve is constructed. We have a set of predictions from a model, and we can vary the threshold for what we consider a positive prediction. For each threshold, we can calculate the TPR and FPR and plot a point on the ROC curve. Connecting these points gives us the full curve.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>ROC Curve</h2>

<img data-src="figs/model_assessment_figs/roc_curve_naive_bayes.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Setting the threshold equal to 0.5, we get an accuracy of 80%. However, the curve indicates a perfect classification performance on this test set. Why is there a discrepancy? The model is not properly calibrated. A threshold of 0.7 has perfect accuracy. We will talk more about calibration later in the lecture.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Area under an ROC curve (AUC)</h2>
<p><br>
</p>

<img data-src="figs/model_assessment_figs/roc_auc.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>The Area Under the Curve (AUC) is a single number summary of the ROC curve. It represents the probability that a randomly chosen positive instance will be ranked higher than a randomly chosen negative instance. An AUC of 1 represents a perfect model, while an AUC of 0.5 represents a model that is no better than random chance.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>ROC curve in sklearn</h2>
<div id="db1c582d" class="cell" data-execution_count="3">
<div class="cell-output cell-output-stdout">
<pre><code></code></pre>
</div>
</div>
<div id="7db7c472" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href=""></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-2"><a href=""></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> RocCurveDisplay</span>
<span id="cb4-3"><a href=""></a></span>
<span id="cb4-4"><a href=""></a>RocCurveDisplay.from_estimator(clf, X_test, y_test, plot_chance_level<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-5"><a href=""></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="week4-model-assessment_files/figure-revealjs/cell-5-output-1.png" width="445" height="431"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>Similar to the confusion matrix, scikit-learn provides a simple way to generate ROC curves. The <code>RocCurveDisplay</code> function can be used to plot the ROC curve for a trained classifier. The <code>plot_chance_level</code> argument is useful to visualize the performance of a random classifier.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Multiclass ROC curve</h2>
<div class="columns">
<div class="column" style="width:65%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/model_assessment_figs/sphx_glr_plot_roc_003.png" class="quarto-figure quarto-figure-center" style="height:100.0%"></p>
</figure>
</div>
</div><div class="column" style="width:35%;">
<p><br>
</p>
<p><strong>Micro-average:</strong> Aggregate contributions of all classes to calculate the metric. Useful if there is class imbalance.</p>
<p><strong>Macro-average:</strong> Compute the metric for each class separately, then take average (treats all classes equally)</p>
</div></div>
<aside class="notes">
<p>For multiclass classification problems, we can’t directly plot a single ROC curve. Instead, we can use techniques like one-vs-rest or one-vs-one to create a curve for each class. We can then average these curves. The micro-average is useful when there is class imbalance, as it aggregates the contributions of all classes. The macro-average treats all classes equally.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="footer">
<p><a href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html">code</a></p>
</div>
</section>
<section class="slide level2">
<h2>ROC Curves: Strengths and Limitations</h2>
<ul>
<li><strong>What they show:</strong> True Positive Rate (TPR) vs.&nbsp;False Positive Rate (FPR)</li>
<li><strong>Best for:</strong> Balanced datasets</li>
<li><strong>Limitation:</strong> Can be misleading on imbalanced datasets because the FPR can be very small, even with a large number of false positives</li>
</ul>
<aside class="notes">
<p>ROC curves are widely used and intuitive, but they have an important limitation. On imbalanced datasets, the false positive rate can appear very small even when the model is making many false positive errors, simply because the denominator (total negatives) is very large. This can make a poor model appear better than it actually is.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Precision-Recall (PR) Curves</h2>
<ul>
<li><strong>What they show:</strong> Precision vs.&nbsp;Recall (TPR)</li>
<li><strong>Best for:</strong> Imbalanced datasets</li>
<li><strong>Advantage:</strong> A model that has high precision and high recall is truly a good model</li>
<li><strong>Research insight:</strong> As mentioned in “Visual methods for analyzing probabilistic classification data” by Alsallakh et al.&nbsp;(2014), PR curves are more informative than ROC curves when dealing with imbalanced datasets</li>
</ul>
<aside class="notes">
<p>Precision-Recall curves are often more informative than ROC curves, especially for imbalanced datasets. They focus directly on the performance for the positive class, which is usually the class of interest in imbalanced problems. The Alsallakh paper provides an excellent discussion on when to use PR curves over ROC curves.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div id="fa2421b3" class="cell" data-execution_count="5">
<div class="cell-output cell-output-stdout">
<pre><code></code></pre>
</div>
</div>
<div id="5d66d8c1" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href=""></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-2"><a href=""></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> PrecisionRecallDisplay</span>
<span id="cb6-3"><a href=""></a></span>
<span id="cb6-4"><a href=""></a>PrecisionRecallDisplay.from_estimator(clf, X_test, y_test)</span>
<span id="cb6-5"><a href=""></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="week4-model-assessment_files/figure-revealjs/cell-7-output-1.png" width="445" height="431"></p>
<figcaption>Precision-Recall Curve</figcaption>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>And here is how you can generate a Precision-Recall curve in scikit-learn. The <code>PrecisionRecallDisplay</code> works similarly to the other display objects we’ve seen. It takes a classifier and test data to generate the curve.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section class="title-slide slide level1 center">
<h1>Visual Analytics Systems for Model Performance</h1>

</section>
<section class="slide level2">
<h2>Squares (2016)</h2>

<img data-src="figs/model_assessment_figs/squares_teaser.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Squares is a visual analytics tool designed to make it easier to analyze the performance of multiclass classifiers. The authors argue that traditional confusion matrices can be hard to interpret, especially when there are many classes. Squares provides a more intuitive and effective way to see not just which classes are being confused, but also the distribution of instances within each cell of the confusion matrix. This helps users to quickly identify the most important errors and prioritize their efforts.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="footer">
<p>Ren, D., Amershi, S., Lee, B., Suh, J., &amp; Williams, J. D. (2016). <em>Squares: Supporting interactive performance analysis for multiclass classifiers</em>. IEEE transactions on visualization and computer graphics.</p>
</div>
</section>
<section class="slide level2">

<iframe data-external="1" src="https://www.youtube.com/embed/yUSwjofGAaQ" width="100%" height="100%" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<aside class="notes">
<p>This video demonstrates the Squares system in action. Pay attention to how the interactive nature of the tool allows for a more in-depth analysis of the classifier’s performance compared to a static confusion matrix.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Alsallakh et. al.&nbsp;(2014)</h2>

<img data-src="figs/model_assessment_figs/Alsallakh_teaser.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>This paper by Alsallakh and his colleagues presents a set of visual methods for analyzing probabilistic classification data. They go beyond simple accuracy metrics to look at the model’s discriminative power and calibration. The key idea is to provide a suite of linked visualizations that allow users to explore the model’s behavior from different perspectives. This includes visualizations of the confusion matrix, feature distributions, and the predicted probabilities themselves.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="footer">
<p>Alsallakh, B., Hanbury, A., Hauser, H., Miksch, S., &amp; Rauber, A. (2014). <a href="../refs/Alsallakh_Hanbury_Hauser_Miksch_Rauber_2014_Visual_Methods_Analyzing_Probabilistic_Classification.pdf"><em>Visual methods for analyzing probabilistic classification data</em></a>. IEEE TVCG.</p>
</div>
</section>
<section class="slide level2">
<h2>Alsallakh et. al.&nbsp;(2014)</h2>

<img data-src="figs/model_assessment_figs/Alsallakh_digits.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Here is an example from the Alsallakh paper, showing how their system can be used to analyze a digit recognition model. You can see the confusion matrix on the left, and on the right, you can see the distribution of instances for a selected class. This allows you to drill down into the data and understand why the model is making certain errors.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="footer">
<p>Alsallakh, B., Hanbury, A., Hauser, H., Miksch, S., &amp; Rauber, A. (2014). <a href="../refs/Alsallakh_Hanbury_Hauser_Miksch_Rauber_2014_Visual_Methods_Analyzing_Probabilistic_Classification.pdf"><em>Visual methods for analyzing probabilistic classification data</em></a>. IEEE TVCG.</p>
</div>
</section>
<section class="slide level2">
<h2>Beauxis-Aussalet and Hardman (2014)</h2>
<p><br>
<br>
</p>

<img data-src="figs/model_assessment_figs/Beauxis_design.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>This paper focuses on the problem of making confusion matrices more accessible to non-expert users. The authors propose a set of design principles for visualizing confusion matrices in a way that is both informative and easy to understand. They emphasize the use of clear labels, intuitive color schemes, and direct display of counts and percentages.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="footer">
<p>Beauxis-Aussalet, E., &amp; Hardman, L. (2014). <a href="../refs/Beauxis_Aussalet_Hardman_2014_Visualization_Confusion_Matrix_Non_Expert_Users.pdf"><em>Visualization of confusion matrix for non-expert users</em></a>. IEEE VAST.</p>
</div>
</section>
<section class="slide level2">
<h2>Beauxis-Aussalet and Hardman (2014)</h2>

<img data-src="figs/model_assessment_figs/confusion_matrix_non_expert.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Here is an example of the kind of visualization proposed by Beauxis-Aussalet and Hardman. It uses a combination of color, size, and text to convey the information in the confusion matrix in a way that is easy to grasp, even for someone who is not an expert in machine learning.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="footer">
<p>Beauxis-Aussalet, E., &amp; Hardman, L. (2014). <a href="../refs/Beauxis_Aussalet_Hardman_2014_Visualization_Confusion_Matrix_Non_Expert_Users.pdf"><em>Visualization of confusion matrix for non-expert users</em></a>. IEEE VAST.</p>
</div>
</section>
<section class="slide level2">
<h2>EnsembleMatrix (2009)</h2>

<img data-src="figs/model_assessment_figs/ensemble_matrix.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>EnsembleMatrix is an interactive visualization tool for working with multiple classifiers. In many real-world applications, you might want to combine the predictions of several different models to get a better result. EnsembleMatrix helps you to understand the strengths and weaknesses of each individual classifier and how they can be combined effectively. It provides a graphical view of the confusion matrices of multiple classifiers, allowing you to compare them and build combination models interactively.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="footer">
<p>Talbot, J., Lee, B., Kapoor, A., &amp; Tan, D. S. (2009). <a href="../refs/Talbot_Lee_Kapoor_Tan_2009_EnsembleMatrix_Interactive_Visualization_Multiple_Classifiers.pdf"><em>EnsembleMatrix: interactive visualization to support machine learning with multiple classifiers</em></a>. CHI.</p>
</div>
</section></section>
<section>
<section class="title-slide slide level1 center">
<h1>Calibration</h1>

</section>
<section class="slide level2">
<h2>What is calibration?</h2>
<ul>
<li><p>When performing classification, we often are interested not only in predicting the class label, but also in the probability of the output</p></li>
<li><p>This probability gives us a kind of confidence score on the prediction</p></li>
<li><p>However, a model can separate the classes well (having a good accuracy/AUC), but be poorly <strong>calibrated</strong>. In this case, the estimated class probabilities are far from the true class probabilities</p></li>
<li><p>We can calibrate the model, changing the scale of the predicted probabilities</p></li>
</ul>
<aside class="notes">
<p>Now we are moving to the third part of our lecture: calibration. Calibration is about whether the probabilities predicted by a model are reliable. For example, if a model predicts a 70% probability of rain, it should rain 70% of the time. A model can be very accurate in its predictions, but still be poorly calibrated. This is a subtle but important point that we will explore in this section.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Calibration - Forecast Example</h2>
<p>Weather forecasters started thinking about calibration a long time ago (Brier, 1950): a forecast of “70% chance of rain” should be followed by rain 70% of the time. Let’s consider a small toy example:</p>
<div class="columns">
<div class="column" style="width:30%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/model_assessment_figs/calibration_forecast_table.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div><div class="column" style="width:70%;">
<p>This forecast is doing at predicting the rain:</p>
<ul>
<li>“10% chance of rain” was a slight over-estimate: <span class="math inline">\((\bar{y} = 0/2 = 0\%)\)</span></li>
<li>“40% chance of rain” was a slight under-estimate: <span class="math inline">\((\bar{y} = 1/2 = 50\%)\)</span></li>
<li>“70% chance of rain” was a slight over-estimate: <span class="math inline">\((\bar{y} = 2/3 = 67\%)\)</span></li>
<li>“90% chance of rain” was a slight under-estimate: <span class="math inline">\((\bar{y} = 1/1 = 100\%)\)</span></li>
</ul>
</div></div>
<aside class="notes">
<p>This is a classic example used to explain calibration. We have a weather forecaster who gives probabilistic predictions of rain. We can check how well calibrated these predictions are by looking at the actual outcomes. For example, for all the days the forecaster predicted a 10% chance of rain, did it actually rain 10% of the time? In this case, the forecaster is not perfectly calibrated, but they are not too far off.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="footer">
<p>Slides based on <a href="https://classifier-calibration.github.io/">classifier-calibration.github.io</a></p>
</div>
</section>
<section class="slide level2">
<h2>Visualizing forecasts - The Reliability Diagram</h2>
<p><br>
</p>
<div class="columns">
<div class="column" style="width:30%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/model_assessment_figs/calibration_forecast_table.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div><div class="column" style="width:70%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/model_assessment_figs/calibration_forecast_reldiagram.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div></div>
<aside class="notes">
<p>A reliability diagram is a standard way to visualize calibration. It plots the observed frequency of an event against the predicted probability of that event. A perfectly calibrated model would have a reliability diagram that is a straight line from (0,0) to (1,1). Deviations from this line indicate miscalibration.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="footer">
<p>Slides based on <a href="https://classifier-calibration.github.io/">classifier-calibration.github.io</a></p>
</div>
</section>
<section class="slide level2">
<h2>Reliability diagram - Changing values</h2>
<p><br>
</p>
<div class="columns">
<div class="column" style="width:30%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/model_assessment_figs/calibration_forecast_table_2.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div><div class="column" style="width:70%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/model_assessment_figs/calibration_forecast_reldiagram_2.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div></div>
<aside class="notes">
<p>In this slide, we see the effect of changing the forecast values on the reliability diagram. Notice how the points on the diagram shift as the forecasts are updated. This provides a direct visual feedback on how changes in the model’s predictions affect its calibration.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="footer">
<p>Slides based on <a href="https://classifier-calibration.github.io/">classifier-calibration.github.io</a></p>
</div>
</section>
<section class="slide level2">
<h2>Reliability diagram - Changing grouping</h2>
<p><br>
</p>
<div class="columns">
<div class="column" style="width:30%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/model_assessment_figs/calibration_forecast_table_2.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div><div class="column" style="width:70%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/model_assessment_figs/calibration_forecast_reldiagram_3.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div></div>
<aside class="notes">
<p>Here, we see another aspect of reliability diagrams: the effect of binning. The way we group the predictions can influence the appearance of the diagram. It’s important to be aware of this and to choose a reasonable number of bins when creating these plots.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="footer">
<p>Slides based on <a href="https://classifier-calibration.github.io/">classifier-calibration.github.io</a></p>
</div>
</section>
<section class="slide level2">
<h2>Reliability Diagram in sklearn</h2>
<div id="4983045e" class="cell" data-execution_count="7">
<div class="cell-output cell-output-stdout">
<pre><code></code></pre>
</div>
</div>
<aside class="notes">
<p>Scikit-learn also provides tools for calibration analysis. Here we are setting up two classifiers, Logistic Regression and Gaussian Naive Bayes, to compare their calibration. We will plot their calibration curves on the next slide.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div id="f8af2ddb" class="cell panel-center" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href=""></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb8-2"><a href=""></a><span class="im">from</span> sklearn.calibration <span class="im">import</span> CalibrationDisplay</span>
<span id="cb8-3"><a href=""></a></span>
<span id="cb8-4"><a href=""></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb8-5"><a href=""></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>)</span>
<span id="cb8-6"><a href=""></a></span>
<span id="cb8-7"><a href=""></a>CalibrationDisplay.from_estimator(lg, X_test, y_test, n_bins<span class="op">=</span><span class="dv">10</span>, ax<span class="op">=</span>ax,</span>
<span id="cb8-8"><a href=""></a>                                  label<span class="op">=</span><span class="st">'Logistic Regression'</span>)</span>
<span id="cb8-9"><a href=""></a>CalibrationDisplay.from_estimator(nb, X_test, y_test, n_bins<span class="op">=</span><span class="dv">10</span>, ax<span class="op">=</span>ax,</span>
<span id="cb8-10"><a href=""></a>                                  label<span class="op">=</span><span class="st">'Naive Bayes'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="week4-model-assessment_files/figure-revealjs/cell-9-output-1.png" width="812" height="429"></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>This code generates the calibration plot, also known as a reliability diagram. We use the <code>CalibrationDisplay</code> from scikit-learn. It plots the predicted probabilities against the true frequency of the positive class. A perfectly calibrated model would follow the diagonal line.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Common sources of miscalibration</h2>
<ul>
<li><p><strong>Underconfidence:</strong> a classifier thinks it’s worse at separating classes than it actually is.</p>
<ul>
<li>Underconfidence typically gives sigmoidal distortions</li>
<li>To calibrate these means to pull predicted probabilities away from the centre</li>
</ul></li>
<li><p><strong>Overconfidence:</strong> a classifier thinks it’s better at separating classes than it actually is</p>
<ul>
<li>Here, distortions are inverse-sigmoidal</li>
<li>Calibrating these means to push predicted probabilities toward the centre</li>
</ul></li>
</ul>
<p>A classifier can be overconfident for one class and underconfident for the other</p>
<aside class="notes">
<p>Miscalibration can occur in two main ways: underconfidence and overconfidence. Underconfident models produce probabilities that are too close to 0.5, while overconfident models produce probabilities that are too close to 0 or 1. The shape of the reliability diagram can help us diagnose which of these problems is occurring.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="footer">
<p>Slides based on <a href="https://classifier-calibration.github.io/">classifier-calibration.github.io</a></p>
</div>
</section>
<section class="slide level2">
<h2>Reliability Diagram in sklearn</h2>

<img data-src="figs/model_assessment_figs/sphx_glr_plot_compare_calibration_001.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>This is an example of a calibration plot from the scikit-learn documentation. It compares the calibration of a Logistic Regression model with a Gaussian Naive Bayes model. You can see that the Logistic Regression model is better calibrated than the Naive Bayes model, as its curve is closer to the diagonal.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<div class="footer">
<p><a href="https://scikit-learn.org/stable/modules/calibration.html">code</a></p>
</div>
</section>
<section class="slide level2">
<h2>Calibration metrics</h2>
<p>Let <span class="math inline">\(N\)</span> be the total of samples, <span class="math inline">\(B\)</span> the number of binds, <span class="math inline">\(n^b\)</span> the samples in bin <span class="math inline">\(b\)</span>, and <span class="math inline">\(conf(b)\)</span> the average predicted probability in bin <span class="math inline">\(b\)</span>.</p>
<ul>
<li>Expected Calibration Error:</li>
</ul>
<p><span class="math inline">\(ECE = \sum_{b=1}^B \frac{n^b}{N}|acc(b) - conf(b)|\)</span></p>
<ul>
<li>Maximum Calibration Error:</li>
</ul>
<p><span class="math inline">\(MCE = \underset{m \in \{1,2,\dots,|B|\}}{\text{max}} |acc(b) - conf(b)|\)</span></p>
<aside class="notes">
<p>Besides visualizing calibration with reliability diagrams, we can also quantify it using metrics like Expected Calibration Error (ECE) and Maximum Calibration Error (MCE). ECE gives an overall measure of miscalibration, while MCE tells us the worst-case deviation.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Calibration of modern models</h2>

<img data-src="figs/model_assessment_figs/calibration_nn_2016.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Guo, C., Pleiss, G., Sun, Y., &amp; Weinberger, K. Q. (2017). <a href="../refs/Guo_Pleiss_Sun_Weinberger_2017_Calibration_Modern_Neural_Networks.pdf"><em>On calibration of modern neural networks</em></a>. ICML.</p>
</div>
</section>
<section class="slide level2">
<h2>Calibration of modern models</h2>
<p><img data-src="figs/model_assessment_figs/calibration_nn_2021_left.png" class="absolute" style="top: 180px; left: 0px; width: 330px; height: 330px; "></p>
<p><img data-src="figs/model_assessment_figs/calibration_nn_2021_right.png" class="absolute" style="top: 170px; left: 330px; width: 800px; height: 350px; "></p>
<div class="footer">
<p>Image taken from Minderer, Matthias, et al.&nbsp;(2021). <em>Revisiting the calibration of modern neural networks</em>. Advances in Neural Information Processing Systems.</p>
</div>
</section>
<section class="slide level2">
<h2>Proper Scoring Rules</h2>
<ul>
<li><p>Proper scoring rules are calculated at the observation level, where as ECE is binned</p></li>
<li><p>Think of them as putting each item in its separate bin, then computing the average of some loss for each predicted probability and its corresponding observed label</p></li>
</ul>

<img data-src="figs/model_assessment_figs/proper_scoring_rules.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on <a href="https://classifier-calibration.github.io/">classifier-calibration.github.io</a></p>
</div>
</section>
<section class="slide level2">
<h2>Proper Scoring Rules</h2>
<ul>
<li>Brier Score/Quadratic error/Euclidean distance:</li>
</ul>
<p><span class="math display">\[BS = \frac{1}{N} \sum_{i=1}^N (\hat{y}_i - y_i)^2\]</span></p>
<ul>
<li><p>Log-loss/Cross entropy:</p>
<ul>
<li><p>Frequently used to as the training loss of machine learning methods, such as neural networks</p></li>
<li><p>Only penalises the probability given to the true class</p></li>
</ul></li>
</ul>
<p><span class="math display">\[LL = -\frac{1}{N} \sum_{i=1}^N [y_i \text{log}(\hat{y}_i) + (1-y_i)\text{log}( 1 - \hat{y}_i)]\]</span></p>
<div class="footer">
<p>Slides based on <a href="https://classifier-calibration.github.io/">classifier-calibration.github.io</a></p>
</div>
</section>
<section class="slide level2">
<h2>Proper Scoring Rules</h2>
<p>An intuitive way to decompose proper scoring rules is into refinement and calibration losses</p>
<ul>
<li><p><strong>Refinement loss:</strong> is the loss due to producing the same probability for instances from different classes</p></li>
<li><p><strong>Calibration loss:</strong> is the loss due to the difference between the probabilities predicted by the model and the proportion of positives among instances with the same output</p></li>
</ul>
<div class="footer">
<p>Slides based on <a href="https://classifier-calibration.github.io/">classifier-calibration.github.io</a></p>
</div>
</section>
<section class="slide level2">
<h2>Calibration Techniques</h2>
<p><strong>Parametric</strong> calibration involves modelling the score distributions within each class</p>
<ul>
<li><p><strong>Platt scaling:</strong> Logistic calibration can be derived by assuming that the scores within both classes are normally distributed with the same variance (Platt, 2000)</p></li>
<li><p><strong>Beta calibration:</strong> employs Beta distributions instead, to deal with scores already on a [0, 1] scale (Kull et al., 2017)</p></li>
<li><p><strong>Dirichlet calibration</strong> for more than two classes (Kull et al., 2019)</p></li>
</ul>
<p><strong>Non-parametric</strong> calibration often ignores scores and employs ranks</p>
<ul>
<li><strong>Isotonic regression</strong> fits a non-parametric isotonic regressor, which outputs a step-wise non-decreasing function</li>
</ul>
<div class="footer">
<p>Slides based on <a href="https://classifier-calibration.github.io/">classifier-calibration.github.io</a></p>
</div>
</section>
<section class="slide level2">
<h2>Platt scaling</h2>
<ul>
<li>Assumes the calibration curve can be corrected by applying a sigmoid to the raw predictions. This means finding <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{b}\)</span> via MLE:</li>
</ul>
<p><span class="math inline">\(p(y_i = 1 | \hat{y}_i) = \frac{1}{1 + exp(\mathbf{A}\hat{y}_i + \mathbf{b})}\)</span></p>
<ul>
<li><p>Works best if the calibration error is symmetrical (classifier output for each binary class is normally distributed with the same variance)</p></li>
<li><p>This can be a problem for highly imbalanced classification problems, where outputs do not have equal variance</p></li>
<li><p>In general it is most effective when the un-calibrated model is under-confident and has similar calibration errors for both high and low outputs</p></li>
</ul>
<aside class="notes">
<p>Platt scaling is a simple and widely used calibration method. It learns a logistic regression model on the outputs of the original model. This method is most effective when the calibration error is symmetric, but it can be less effective for imbalanced datasets.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Isotonic regression</h2>
<ul>
<li><p>Fits a non-parametric isotonic regressor, which outputs a step-wise non-decreasing function</p></li>
<li><p>Isotonic regression is more general when compared to Platt scaling, as the only restriction is that the mapping function is monotonically increasing</p></li>
<li><p>Is more powerful as it can correct any monotonic distortion of the un-calibrated model</p></li>
<li><p>However, it is more prone to overfitting, especially on small datasets</p></li>
</ul>
<aside class="notes">
<p>Isotonic regression is a more powerful, non-parametric calibration method. It can correct any monotonic distortion in the model’s outputs. However, because it is more flexible, it is also more prone to overfitting, especially when the dataset is small.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Calibration in sklearn</h2>

<img data-src="figs/model_assessment_figs/sphx_glr_plot_calibration_curve_001.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p><a href="https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html">code</a></p>
</div>
</section>
<section class="slide level2">
<h2>Calibration in sklearn</h2>

<img data-src="figs/model_assessment_figs/sphx_glr_plot_calibration_curve_002.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p><a href="https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html">code</a></p>
</div>
</section>
<section class="slide level2">
<h2>Calibration Takeaways</h2>
<ul>
<li><p>Reliability diagrams are a standard way to visualize calibration</p></li>
<li><p>ECE is a summary of what reliability diagrams show</p></li>
<li><p>Proper scoring rules (Log loss, Brier score) measure different aspects of probability correctness</p></li>
<li><p>However, proper scoring rules cannot tell us where a model is miscalibrated</p></li>
</ul>
<aside class="notes">
<p>To summarize the key points on calibration: reliability diagrams are the primary tool for visualizing calibration. ECE and MCE are metrics to quantify it. Proper scoring rules like Brier score and log-loss provide a more detailed view of the correctness of the predicted probabilities. And finally, there are different techniques to calibrate a model, each with its own trade-offs.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Hyperparameters of reliability diagrams</h2>
<p><br>
</p>

<img data-src="figs/model_assessment_figs/calibrate_reliability_hyperparameters.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Image taken from Xenopoulos, P., Rulff, J., Nonato, L. G., Barr, B., &amp; Silva, C. (2022). <em>Calibrate: Interactive analysis of probabilistic model output</em>. IEEE Transactions on Visualization and Computer Graphics.</p>
</div>
</section>
<section class="slide level2">
<h2>Calibrate (2023)</h2>

<img data-src="figs/model_assessment_figs/calibrate_teaser.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Xenopoulos, P., Rulff, J., Nonato, L. G., Barr, B., &amp; Silva, C. (2022). <a href="../refs/Xenopoulos_Rulff_Nonato_Barr_Silva_2022_Calibrate_Interactive_Analysis_Probabilistic_Output.pdf"><em>Calibrate: Interactive analysis of probabilistic model output</em></a>. IEEE TVCG.</p>
</div>
</section>
<section class="slide level2">
<h2>Calibrate (2023) - Learned Reliability Diagram</h2>

<img data-src="figs/model_assessment_figs/calibrate_learned_rel_diag.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Xenopoulos, P., Rulff, J., Nonato, L. G., Barr, B., &amp; Silva, C. (2022). <a href="../refs/Xenopoulos_Rulff_Nonato_Barr_Silva_2022_Calibrate_Interactive_Analysis_Probabilistic_Output.pdf"><em>Calibrate: Interactive analysis of probabilistic model output</em></a>. IEEE TVCG.</p>
</div>
</section>
<section class="slide level2">
<h2>Calibrate (2023)</h2>
<video id="video_shortcode_videojs_video1" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="figs/model_assessment_figs/vis22a-sub1657-i7.mp4"></video>
<div class="footer">
<p>Xenopoulos, P., Rulff, J., Nonato, L. G., Barr, B., &amp; Silva, C. (2022). <a href="../refs/Xenopoulos_Rulff_Nonato_Barr_Silva_2022_Calibrate_Interactive_Analysis_Probabilistic_Output.pdf"><em>Calibrate: Interactive analysis of probabilistic model output</em></a>. IEEE TVCG.</p>
</div>
</section>
<section class="slide level2">
<h2>Smooth ECE (2023)</h2>
<p><br>
</p>

<img data-src="figs/model_assessment_figs/smoothece_teaser.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Błasiok, J., &amp; Nakkiran, P. (2023). <em>Smooth ECE: Principled Reliability Diagrams via Kernel Smoothing</em>. arXiv preprint arXiv:2309.12236.</p>
</div>
</section>
<section class="slide level2">
<h2>Smooth ECE (2023)</h2>
<p><br>
</p>

<img data-src="figs/model_assessment_figs/smoothece_smoothing.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Błasiok, J., &amp; Nakkiran, P. (2023). <em>Smooth ECE: Principled Reliability Diagrams via Kernel Smoothing</em>. arXiv preprint arXiv:2309.12236.</p>
</div>
</section>
<section class="slide level2">
<h2>Visualizing Calibration for Multi-Class Problems</h2>

<img data-src="figs/model_assessment_figs/calibration_multiclass.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Vaicenavicius, J., Widmann, D., Andersson, C., et al.&nbsp;(2019). <a href="../refs/Vaicenavicius_Widmann_Andersson_Lindsten_Roll_Schon_2019_Evaluating_Model_Calibration.pdf"><em>Evaluating model calibration in classification</em></a>. AISTATS.</p>
</div>
</section>
<section class="slide level2">
<h2>Suggested Calibration Literature</h2>
<ul>
<li><p>Niculescu-Mizil, A., &amp; Caruana, R. (2005). <a href="../refs/Niculescu_Mizil_Caruana_2005_Predicting_Good_Probabilities_Supervised_Learning.pdf">Predicting good probabilities with supervised learning</a>. ICML.</p></li>
<li><p>Nixon, J., Dusenberry, M. W., Zhang, L., Jerfel, G., &amp; Tran, D. (2019, June). <a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/Uncertainty%20and%20Robustness%20in%20Deep%20Visual%20Learning/Nixon_Measuring_Calibration_in_Deep_Learning_CVPRW_2019_paper.pdf">Measuring Calibration in Deep Learning</a>. In CVPR Workshops (Vol. 2, No.&nbsp;7).</p></li>
<li><p>Guo, C., Pleiss, G., Sun, Y., &amp; Weinberger, K. Q. (2017). <a href="../refs/Guo_Pleiss_Sun_Weinberger_2017_Calibration_Modern_Neural_Networks.pdf">On calibration of modern neural networks</a>. ICML.</p></li>
<li><p>Vaicenavicius, J., Widmann, D., Andersson, C., Lindsten, F., Roll, J., &amp; Schön, T. (2019, April). <a href="http://proceedings.mlr.press/v89/vaicenavicius19a/vaicenavicius19a.pdf">Evaluating model calibration in classification</a>. In The 22nd International Conference on Artificial Intelligence and Statistics (pp.&nbsp;3459-3467). PMLR.</p></li>
</ul>
<aside class="notes">
<p>This slide provides a list of important papers on calibration. The Niculescu-Mizil and Caruana paper is a classic in this area. The other papers discuss more recent work on calibration, especially in the context of deep learning.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">
<h2>Suggested Calibration Literature</h2>
<ul>
<li><p>Kull, M., &amp; Flach, P. (2015). <a href="../refs/Kull_Flach_2015_Novel_Decompositions_Proper_Scoring_Rules.pdf">Novel decompositions of proper scoring rules for classification</a>. ECML-PKDD.</p></li>
<li><p><a href="../refs/Silva_Filho_2020_ECML_PKDD_Tutorial_Evaluation_Metrics.pdf">ECML/PKDD 2020 Tutorial: Evaluation metrics and proper scoring rules</a></p></li>
<li><p><a href="https://colab.research.google.com/drive/1mqDVJICMBg2eoIr2VPaDjQFUzlDT3grc?usp=sharing">Google Colab notebook for calibration curves</a></p></li>
<li><p>Kull, M., &amp; Flach, P. (2015, September). <a href="https://link.springer.com/content/pdf/10.1007/978-3-319-23528-8_5.pdf">Novel decompositions of proper scoring rules for classification: Score adjustment as precursor to calibration</a>. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp.&nbsp;68-85). Springer, Cham.</p></li>
<li><p><a href="https://classifier-calibration.github.io/assets/slides/clacal_tutorial_ecmlpkdd_2020_evaluation.pdf">ECML/PKDD 2020 Tutorial: Evaluation metrics and proper scoring rules</a></p></li>
</ul>
<aside class="notes">
<p>Here are a few more resources for those interested in diving deeper into calibration. The ECML/PKDD tutorial is a great starting point, and the Google Colab notebook provides a hands-on introduction to calibration curves.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>

</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="figs/vida.jpg" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://engineering.nyu.edu" class="uri">https://engineering.nyu.edu</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="week4-model-assessment_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="week4-model-assessment_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="week4-model-assessment_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="week4-model-assessment_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="week4-model-assessment_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="week4-model-assessment_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="week4-model-assessment_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="week4-model-assessment_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="week4-model-assessment_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="week4-model-assessment_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'fast',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script>videojs(video_shortcode_videojs_video1);</script>
    

</body></html>