<!DOCTYPE html>
<html lang="en"><head>
<script src="week2-infovis_files/libs/clipboard/clipboard.min.js"></script>
<script src="week2-infovis_files/libs/quarto-html/tabby.min.js"></script>
<script src="week2-infovis_files/libs/quarto-html/popper.min.js"></script>
<script src="week2-infovis_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="week2-infovis_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="week2-infovis_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="week2-infovis_files/libs/quarto-html/quarto-syntax-highlighting-c8ad9e5dbd60b7b70b38521ab19b7da4.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="week2-infovis_files/libs/quarto-contrib/videojs/video.min.js"></script>
<link href="week2-infovis_files/libs/quarto-contrib/videojs/video-js.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.34">

  <meta name="author" content="Claudio Silva">
  <meta name="dcterms.date" content="2025-11-10">
  <title>Visualization for NLP and LLMs</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="week2-infovis_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="week2-infovis_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="week2-infovis_files/libs/revealjs/dist/theme/quarto-495a6a6110b82aac69f506856e9beb96.css">
  <link href="week2-infovis_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="week2-infovis_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="week2-infovis_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="week2-infovis_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section class="quarto-title-block center">
  <h1 class="title">Visualization for NLP and LLMs</h1>
  <p class="subtitle">CS-GY 9223 - Fall 2025</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Claudio Silva 
</div>
        <p class="quarto-title-affiliation">
            NYU Tandon School of Engineering
          </p>
    </div>
</div>

  <p class="date">November 10, 2025</p>
</section>
<section class="slide level2">
<h2>What is Information Visualization? Why Use It?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>“The use of computer-supported, interactive, visual representations of abstract data to amplify cognition.”</p>
</div><div class="column" style="width:40%;">
<p><img data-src="figs/infovis.jpg"></p>
</div></div>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Key Concepts</h2>
<ul>
<li>Computer-Based</li>
<li>Visual Representation</li>
<li>Abstract Data</li>
<li>Interactive</li>
<li>Amplify Cognition</li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Abstract Data</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Data with no obvious/natural visual representation</p>
</div><div class="column" style="width:50%;">
<p><img data-src="figs/spreadsheet.jpg"> <img data-src="figs/deepwork.jpg"></p>
</div></div>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Abstract Data</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Data with no obvious/natural visual representation</p>
</div><div class="column" style="width:40%;">
<p><img data-src="figs/chest.jpg"></p>
</div></div>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Interactive</h2>
<p>Users can change what is visualized and how it is visualized.</p>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">

<video id="video_shortcode_videojs_video1" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="figs/taxivis.mp4"></video>
</section>
<section class="slide level2">
<h2>Amplify Cognition</h2>
<ul>
<li class="fragment">Solve problems with data with less effort, in a shorter time, and more accurately.</li>
<li class="fragment">… or even be able to do things it would be impossible to do without a computer and a graphical representation.</li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Cognitive artifacts: tools that help us think!</h2>
<ul>
<li class="fragment">Try to multiply 34 x 72 using exclusively your mind …</li>
<li class="fragment">… now do it again using pen and paper.
<ul>
<li class="fragment"><img data-src="figs/multiplication.jpg"></li>
</ul></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Why is it easier?</h2>
<ul>
<li class="fragment">… because we can store intermediary results in the paper rather than keeping the information in mind. That is, part of the memory is in the world rather than in your head.</li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Let’s play the “game of 15” …</h2>
<ul>
<li class="fragment">The “pieces” for the game are the nine digits: 1, 2, 3, 4, 5, 6, 7, 8, 9. Each player takes a digit in turn. Once a digit is taken, it cannot be used by the other player. The first player to get three digits that sum to 15 wins.</li>
<li class="fragment">Here is a sample game: Player A takes 8. Player B takes 2. Then A takes 4, and B takes 3. A takes 5.</li>
<li class="fragment">Question 1: Suppose you are now to step in and play for B. What move would you make?</li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Let’s play a different game: tic-tac-toe</h2>
<div class="columns">
<div class="column" style="width:70%;">
<p>Players alternately place an O or a X in one of nine spaces arranged in a rectangular array. Once a space has been taken, it cannot be changed by either player. The first player to get three symbols in a straight line wins. Suppose player A is X and B is O, and the game has reached the state on the right.</p>
<p>Question 2: Suppose you are now to step in and play an O for B. What move would you make?</p>
</div><div class="column" style="width:20%;">
<p><img data-src="figs/tictactoe.jpg"></p>
</div></div>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Problem Isomorphs <a href="https://en.wikipedia.org/wiki/Herbert_A._Simon">Herbert Simon</a></h2>
<ul>
<li class="fragment">The two problems are equivalent!</li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Why use visualization?</h2>
<ul>
<li>Explanatory visualization</li>
<li>Exploratory visualization</li>
<li>Confirmatory visualization</li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Great Explanatory Visualizations</h2>
<ul>
<li><p>NYT: https://flowingdata.com/tag/new-york-times/</p></li>
<li><p>Washington Post: http://postgraphics.tumblr.com/</p></li>
<li><p>Gregor Aisch: https://driven-by-data.net/</p></li>
<li><p>Nicky Case/Explorable Explanations: http://explorabl.es/</p></li>
<li><p>Polygraph: http://polygraph.cool/ &amp; https://pudding.cool/</p></li>
<li><p>ProPublica: https://www.propublica.org/</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Why use a graphical representation?</h2>
<ul>
<li>Large parts of our brain are devoted to spatial processing</li>
</ul>

<img data-src="figs/visualbrain.jpg" class="r-stretch"><div class="footer">
<p>Via Wikipedia, By OpenStax College - Anatomy &amp; Physiology, Connexions Web site., Jun 19, 2013., CC BY 3.0</p>
</div>
</section>
<section class="slide level2">
<h2>Why use a computer to visualize data?</h2>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Why use interaction?</h2>
<ul>
<li><p>Each visualization can only answer a subset of questions.</p></li>
<li><p>With interaction the user can change what is visualized and how to answer a multitude of questions.</p></li>
<li><p>Also one cannot visualize everything at once.</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>How do you assess the quality of a visualization?</h2>
<ul>
<li>Isn’t it subjective? Some people like A, whereas some others like B.</li>
</ul>
<ul>
<li class="fragment">Some visual representations are better than others at solving particular problems …</li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Digression: Graphical Perception</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/cleveland-book-cover.jpg"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="figs/cleveland-mcgill-paper.jpg"></p>
</div></div>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Graphical Perception Experiment</h2>

<img data-src="figs/cleveland-mcgill-a-vs-b-examples.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Graphical Perception Results</h2>
<p><img data-src="figs/cleveland-mcgill-a-vs-b-examples.jpg"></p>
<p><img data-src="figs/cleveland-mcgill-a-vs-b-results.jpg"></p>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Designing effective visualizations requires</h2>
<ul>
<li class="fragment">Knowing the design space</li>
<li class="fragment">Being able to compare the solutions</li>
<li class="fragment">… in turn comparing the solutions requires understanding human perception.</li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Data Types</h2>
<ul>
<li><p>The first ingredient in effective visualization is the input data. Data values can represent different forms of measurement.</p></li>
<li><p>What kinds of comparisons do those measurements support?</p></li>
<li><p>What kinds of visual encodings then support those comparisons?</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Jeffrey Heer <a href="https://observablehq.com/@uwdata/data-types-graphical-marks-and-visual-encoding-channels">link</a></p>
</div>
</section>
<section class="slide level2">
<h2>Nominal (N) or Categorical (C)</h2>
<ul>
<li><p>Nominal data — also called categorical data — consist of category names.</p></li>
<li><p>With nominal data we can compare the equality of values: is value A the same or different than value B? (A = B), supporting statements like “A is equal to B” or “A is not equal to B”.</p></li>
<li><p>When visualizing nominal data we should readily perceive if values are the same or different: position, color hue (blue, red, green, etc.), and shape are all reasonable options.</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Jeffrey Heer <a href="https://observablehq.com/@uwdata/data-types-graphical-marks-and-visual-encoding-channels">link</a></p>
</div>
</section>
<section class="slide level2">
<h2>Ordinal (O)</h2>
<ul>
<li><p>Ordinal data consist of values that have a specific ordering.</p></li>
<li><p>With ordinal data we can compare the rank-ordering of values: does value A come before or after value B? (A &lt; B), supporting statements like “A is less than B” or “A is greater than B”.</p></li>
<li><p>When visualizing ordinal data, we should perceive a sense of rank-order. Position, size, or color value (brightness) might be appropriate, whereas color hue (which is not perceptually ordered) would be less appropriate.</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Jeffrey Heer <a href="https://observablehq.com/@uwdata/data-types-graphical-marks-and-visual-encoding-channels">link</a></p>
</div>
</section>
<section class="slide level2">
<h2>Quantitative (Q)</h2>
<ul>
<li><p>With quantitative data we can measure numerical differences among values.</p></li>
<li><p>There are multiple sub-types of quantitative data:</p>
<ul>
<li>For interval data we can measure the distance between points: (A - B).</li>
<li>For ratio data we can also measure proportions or scale factors: (A / B).</li>
</ul></li>
<li><p>Quantitative values can be visualized using position, size, or color value, among other channels. An axis with a zero baseline is essential for proportional comparisons of ratio values, but can be safely omitted for interval comparisons.</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Jeffrey Heer <a href="https://observablehq.com/@uwdata/data-types-graphical-marks-and-visual-encoding-channels">link</a></p>
</div>
</section>
<section class="slide level2">
<h2>Temporal (T)</h2>
<ul>
<li><p>Temporal values measure time points or intervals. This type is a special case of quantitative values (timestamps) with rich semantics and conventions (i.e., the Gregorian calendar).</p></li>
<li><p>Example temporal values include date strings such as “2019-01-04” and “Jan 04 2019”, as well as standardized date-times such as the ISO date-time format: “2019-01-04T17:50:35.643Z”. There are no temporal values in our global development dataset above, as the year field is encoded as an integer.</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Jeffrey Heer <a href="https://observablehq.com/@uwdata/data-types-graphical-marks-and-visual-encoding-channels">link</a></p>
</div>
</section>
<section class="slide level2">
<h2>Spatial (S)</h2>
<ul>
<li><p>Data that can be shown in a map</p></li>
<li><p>Also known as geospatial data, refers to information that identifies the geographic location and characteristics of natural or constructed features and boundaries on the Earth. <a href="https://atlan.com/spatial-data/">https://atlan.com/spatial-data/</a></p></li>
</ul>
</section>
<section class="slide level2">
<h2>Data Types Summary</h2>
<ul>
<li><p>These data types are not mutually exclusive, but rather form a hierarchy: ordinal data support nominal (equality) comparisons, while quantitative data support ordinal (rank-order) comparisons.</p></li>
<li><p>Moreover, these data types do not provide a fixed categorization. For example, just because a data field is represented using a number doesn’t mean we have to treat it as a quantitative type! We might interpret a set of ages (10 years old, 20 years old, etc.) as nominal (underage or overage), ordinal (grouped by year), or quantitative (calculate average age).</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Jeffrey Heer <a href="https://observablehq.com/@uwdata/data-types-graphical-marks-and-visual-encoding-channels">link</a></p>
</div>
</section>
<section class="slide level2">
<h2>Fundamental Charts</h2>
<ul>
<li><p>Widely adopted, effective, useful.</p></li>
<li><p>Solve very large percentage of vis problems.</p></li>
<li><p>Training ground for more sophisticated graphs.</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Bar Chart</h2>
<div class="columns">
<div class="column" style="width:40%;">
<ul>
<li>Visualize how a quantity distributes across a set of categories.</li>
</ul>
</div><div class="column" style="width:60%;">
<p><img data-src="figs/barchart.jpg"></p>
</div></div>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Line Chart</h2>
<ul>
<li>Visualize how a quantity changes in relation to another quantity (typically time).</li>
</ul>

<img data-src="figs/linechart.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Scatter Plot</h2>
<div class="columns">
<div class="column" style="width:40%;">
<ul>
<li>Visualize how a quantity relate to another quantity.</li>
</ul>
</div><div class="column" style="width:60%;">
<p><img data-src="figs/scatterplot.jpg"></p>
</div></div>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Matrix</h2>
<ul>
<li>Visualize how a quantity distributes across two categories.</li>
</ul>

<img data-src="figs/matrixchart.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Symbol Map</h2>
<div class="columns">
<div class="column" style="width:40%;">
<ul>
<li>Visualize how a quantity distributes across two spatial coordinates.</li>
</ul>
</div><div class="column" style="width:60%;">
<p><img data-src="figs/symbolmap.jpg"></p>
</div></div>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Fundamental Graphs Summary</h2>

<img data-src="figs/plots-vs-datatypes.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Scatter Plots + Faceting (without)</h2>

<img data-src="figs/scatterplot-simple.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Scatter Plots + Faceting (with)</h2>

<img data-src="figs/scatterplot-facet.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Tidy Data</h2>
<ul>
<li>Goal: organizing data to make visualization easier</li>
</ul>

<img data-src="figs/tidydata-paper.jpg" class="r-stretch"><p><a href="https://vita.had.co.nz/papers/tidy-data.pdf">link to paper</a></p>
<div class="footer">
<p>Slides based on material from Hadley Wickham</p>
</div>
</section>
<section class="slide level2">
<h2>Tidy Data</h2>

<img data-src="figs/td-table-typical.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Hadley Wickham</p>
</div>
</section>
<section class="slide level2">
<h2>Tidy Data</h2>

<img data-src="figs/td-table-alternative.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Hadley Wickham</p>
</div>
</section>
<section class="slide level2">
<h2>Tidy Data</h2>

<img data-src="figs/td-table-tidy.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Hadley Wickham</p>
</div>
</section>
<section class="slide level2">
<h2>Tidy Data: Definition</h2>
<p>In tidy data:</p>
<ul>
<li><p>Each variable forms a column.</p></li>
<li><p>Each observation forms a row.</p></li>
<li><p>Each type of observational unit forms a table.</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Hadley Wickham</p>
</div>
</section>
<section class="slide level2">
<h2>Tidy Data: Example #1</h2>

<img data-src="figs/td-table-example.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Hadley Wickham</p>
</div>
</section>
<section class="slide level2">
<h2>Tidy Data</h2>

<img data-src="figs/td-table-towards-tidy.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Hadley Wickham</p>
</div>
</section>
<section class="slide level2">
<h2>Tidy Data: Example #2</h2>

<img data-src="figs/td-table-before-tidy.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Hadley Wickham</p>
</div>
</section>
<section class="slide level2">
<h2>Tidy Data</h2>

<img data-src="figs/td-table-after-tidy.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Hadley Wickham</p>
</div>
</section>
<section class="slide level2">
<h2>Graphical Encoding</h2>
<p>Every visualization can be described in terms of:</p>
<ul>
<li><p>its basic graphical components</p></li>
<li><p>mapping strategy between data and graphics</p></li>
<li><p>more precisely, a set of mappings between:</p>
<ul>
<li>data items — visual marks</li>
<li>data attributes — visual channels</li>
</ul></li>
</ul>
<div class="footer">
<p>Slides based on material from Hadley Wickham</p>
</div>
</section>
<section class="slide level2">
<h2>Graphical Marks</h2>

<img data-src="figs/marks.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Visual Encoding Channels</h2>

<img data-src="figs/channels.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Visualization Decoding</h2>
<ul>
<li><p>Marks — Data Items</p></li>
<li><p>Channels — Data Attributes</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Examples</h2>

<img data-src="figs/usainboltnyt.jpg" class="r-stretch"><p><a href="http://www.nytimes.com/interactive/2012/08/05/sports/olympics/the-100-meter-dash-one-race-every-medalist-ever.html?_r=0">NYT link</a></p>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Expressiveness Principle</h2>
<p>The visual representation should express the type of information that exists in the data.</p>
<ul>
<li>Ordered data should not appear as unordered.</li>
<li>Unordered data should not appear as ordered.</li>
</ul>
</section>
<section class="slide level2">
<h2>Effectiveness Principle</h2>
<p>Relevance of information should match the effectiveness of the channels used.</p>
<ul>
<li>Represent important information with more effective channels</li>
</ul>
</section>
<section class="slide level2">
<h2>Effectiveness Effect</h2>

<img data-src="figs/effectiveness.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Summary</h2>
<ul>
<li>Visual Encoding/Decoding</li>
<li>Graphical Marks and Channels</li>
<li>Expressiveness and Effectiveness</li>
<li>Channels Appropriateness and Ranking</li>
<li>Evaluation and Design</li>
<li>Contextual Components
<ul>
<li>Labels, legends and annotations</li>
<li>Axes, grids and trend lines</li>
</ul></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Neo: Interactive Confusion Matrices</h2>
<p>Great example of research in VisML!</p>
<p><a href="https://www.youtube.com/watch?v=LmsJJDHfGlI">video link</a></p>
</section>
<section class="slide level2">

<iframe data-external="1" src="https://www.youtube.com/embed/LmsJJDHfGlI" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

</section>
<section class="slide level2">
<h2>Perception for Design</h2>

<img data-src="figs/colinwarebook.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Brain</h2>
<p>“Visual thinking consists of a series of acts of attention, driving eye movements, and tuning our pattern finding circuits”, Colin Aware</p>

<img data-src="figs/brain.jpg" class="r-stretch"><div class="footer">
<p>Image from Wikipedia: <a href="https://en.wikipedia.org/wiki/Human_brain">link</a></p>
</div>
</section>
<section class="slide level2">
<h2>The Vision Brain</h2>
<p>“Visual thinking consists of a series of acts of attention, driving eye movements, and tuning our pattern finding circuits”, Colin Aware</p>

<img data-src="figs/visualbrain.jpg" class="r-stretch"><div class="footer">
<p>Image from Wikipedia: <a href="https://en.wikipedia.org/wiki/Human_brain">link</a></p>
</div>
</section>
<section class="slide level2">
<h2>The Act of Perception</h2>
<ul>
<li>Botton-Up and Top-Down Processes</li>
</ul>

<img data-src="figs/actofperception.jpg" class="r-stretch"><div class="footer">
<p>Material from Colin Ware’s book</p>
</div>
</section>
<section class="slide level2">
<h2>The Act of Perception</h2>
<ul>
<li>Bottom-up: information is sucessively selected and filtered into patterns as it passes a sequence of stages. Ware outlines three stages: 1) optical nerve to V1 Cortex; 2) use texture and colors to aggregate <em>patterns</em>; 3) visual objects are recognized in the <em>visual working memory</em>.</li>
</ul>

<img data-src="figs/facevase-illusion.jpg" class="r-stretch"><div class="footer">
<p>Image from the book: “Eye and Brain: The Psychology of Seeing”, Gregory</p>
</div>
</section>
<section class="slide level2">
<h2>The Act of Perception</h2>
<ul>
<li>Top-Down: Every stage of bottom-up processing contains a corresponding top-down process. Ware describes the process as “attention”. The dominant principle is that we only get the information that we need, when we need it.</li>
</ul>

<img data-src="figs/eyemovements.jpg" class="r-stretch"><div class="footer">
<p>Material from Colin Ware’s book</p>
</div>
</section>
<section class="slide level2">
<h2>The Implications for Design</h2>
<ul>
<li><p>“Just-in-time visual queries” (Ware)</p></li>
<li><p>“One way to look at the brain operates is a set of nested loops. Outer loops deal with generality while inner loops process detail.” (Ware)</p></li>
</ul>

<img data-src="figs/brainproblemsolvingloop.jpg" class="r-stretch"><div class="footer">
<p>Material from Colin Ware’s book</p>
</div>
</section>
<section class="slide level2">
<h2>Low-Level Feature Analysis</h2>
<ul>
<li>David Hubel and Torsten Wiesel won Nobel prize for this discovery.</li>
</ul>

<img data-src="figs/v1-cortical-layer.jpg" class="r-stretch"><div class="footer">
<p>Material from Colin Ware’s book</p>
</div>
</section>
<section class="slide level2">
<h2>What and Where Pathways</h2>
<ul>
<li>What: identification of objects in environment.</li>
<li>Where: location of objects and eye movement.</li>
</ul>

<img data-src="figs/what-and-where-pathway.jpg" class="r-stretch"><div class="footer">
<p>Material from Colin Ware’s book</p>
</div>
</section>
<section class="slide level2">
<h2>What Stands Out (Popout)</h2>
<ul>
<li>Anne Triesman studied how to find patterns and shapes when surrounded by others.</li>
</ul>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/popout.jpg"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="figs/popout7.jpg"></p>
</div></div>
<p>For some configurations the time <em>did not</em> depend on the number of distracters (pre-attentive).</p>
<div class="footer">
<p>Material from Colin Ware’s book</p>
</div>
</section>
<section class="slide level2">
<h2>What Stands Out (Popout)</h2>

<img data-src="figs/preattentive-vs-not.jpg" class="r-stretch"><div class="footer">
<p>Material from Colin Ware’s book</p>
</div>
</section>
<section class="slide level2">
<h2>The Gestalt Principles <a href="https://www.interaction-design.org/literature/topics/gestalt-principles">link, see video</a></h2>
<ul>
<li>Visualization is a two-way street:
<ul>
<li>We (the vis designer) bring something to the table.</li>
<li>The human (end user) brings their prior experience.</li>
</ul></li>
<li>Design should take such prior experience into account!</li>
<li>What is prior experience? Gestalt laws.</li>
</ul>
<div class="footer">
<p>Material from Matt Berger</p>
</div>
</section>
<section class="slide level2">
<h2>Closure</h2>
<ul>
<li>We can complete incomplete shapes</li>
</ul>

<img data-src="figs/closure.jpg" class="r-stretch"><ul>
<li>Implications: visualizations can be unintentionally misleading! Conversely: sometimes only necessary to show sparse set of marks to convey trend (dot plot)</li>
</ul>
<div class="footer">
<p>Material from Matt Berger</p>
</div>
</section>
<section class="slide level2">
<h2>Similarity</h2>
<ul>
<li>Elements with the same visual properties considered to be grouped</li>
</ul>

<img data-src="figs/similarity.jpg" class="r-stretch"><div class="footer">
<p>Material from Matt Berger</p>
</div>
</section>
<section class="slide level2">
<h2>Similarity</h2>
<ul>
<li>Elements with the same visual properties considered to be grouped</li>
</ul>

<img data-src="figs/similarity-example.jpg" class="r-stretch"><div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Proximity</h2>
<ul>
<li>Elements that are of close spatial proximity are somehow grouped.</li>
</ul>

<img data-src="figs/proximity.jpg" class="r-stretch"><div class="footer">
<p>Material from Matt Berger</p>
</div>
</section>
<section class="slide level2">
<h2>Proximity</h2>
<ul>
<li>Elements that are of close spatial proximity are somehow grouped.</li>
</ul>

<img data-src="figs/proximity-example.jpg" class="r-stretch"><div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Enclosure</h2>
<ul>
<li>Explicit visual encoding of enclosure also depicts grouping.</li>
</ul>

<img data-src="figs/enclosure.jpg" class="r-stretch"><div class="footer">
<p>Material from Matt Berger</p>
</div>
</section>
<section class="slide level2">
<h2>Enclosure</h2>
<ul>
<li>Explicit visual encoding of enclosure also depicts grouping.</li>
</ul>

<img data-src="figs/bubblesets.jpg" class="r-stretch"><p><a href="https://www.youtube.com/watch?v=P6CgBmIiXaE">Bubblesets video link</a></p>
<div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Connection</h2>
<ul>
<li>Objects connected together are perceived as a group.</li>
</ul>

<img data-src="figs/connection.jpg" class="r-stretch"><div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Connection</h2>
<ul>
<li>Objects connected together are perceived as a group.</li>
</ul>

<img data-src="figs/connection2.jpg" class="r-stretch"><div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Connection</h2>
<ul>
<li>Objects connected together are perceived as a group.</li>
</ul>

<img data-src="figs/connection3.jpg" class="r-stretch"><div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Connection</h2>
<ul>
<li>Objects connected together are perceived as a group.</li>
</ul>

<img data-src="figs/connection4.jpg" class="r-stretch"><div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Just Noticeable Difference (JND)</h2>
<ul>
<li><p>In psychophysics a just-noticeable difference or JND is the amount something must be changed in order for a difference to be noticeable, detectable at least half the time.</p></li>
<li><p>Stevens’s power law: <a href="https://en.wikipedia.org/wiki/Stevens%27s_power_law">link</a></p></li>
</ul>

<img data-src="figs/psychophysical-law.jpg" class="r-stretch"><div class="footer">
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Just-noticeable_difference">link</a></p>
</div>
</section>
<section class="slide level2">
<h2>Accuracy</h2>
<ul>
<li>How accurately a channel can express quantitative information</li>
</ul>
</section>
<section class="slide level2">
<h2>Graphical Perception</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/cleveland-book-cover.jpg"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="figs/cleveland-mcgill-paper.jpg"></p>
</div></div>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Graphical Perception Experiment</h2>

<img data-src="figs/cleveland-mcgill-a-vs-b-examples.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Graphical Perception Results</h2>
<p><img data-src="figs/cleveland-mcgill-a-vs-b-examples.jpg"></p>
<p><img data-src="figs/cleveland-mcgill-a-vs-b-results.jpg"></p>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Accuracy</h2>
<ul>
<li><p>Position &gt; Length and Angle &gt; Area</p></li>
<li><p>Prioritize high-rank channels (with reason)</p></li>
<li><p>Do not expect precise judgments from low-rank channels</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Effectiveness Effect</h2>

<img data-src="figs/effectiveness.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Discriminability</h2>
<ul>
<li><p>How many distinct values can be distinguished within a channel</p></li>
<li><p>It depends on:</p>
<ul>
<li>Channel properties</li>
<li>Spatial arrangement</li>
<li>Size (resolution)</li>
<li>Cardinality</li>
</ul></li>
<li><p>Warning: Do not overestimate the number of values viewers can perceive/discriminate</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Discriminability</h2>
<ul>
<li>Many channels, in particular identity channels, can only support a limited number of discriminable levels.
<ul>
<li>Line width is one of the most limited with perhaps 3 levels.</li>
<li>Using more than 5 or 6 color hues is not recommended.</li>
<li>Similarly, using more than 5 or 6 symbol shapes can create difficulties.</li>
</ul></li>
<li>If the number of levels that can be represented by a channel is smaller than the number of attribute levels then some form of meaningful aggregation is needed.</li>
</ul>
<div class="footer">
<p>Material from <a href="https://homepage.divms.uiowa.edu/~luke/classes/STAT4580/percep.html#discriminability">link</a></p>
</div>
</section>
<section class="slide level2">
<h2>Popout</h2>
<ul>
<li><p>Tasks performed in less than 200 to 250 milliseconds.</p></li>
<li><p>Faster than eyes movement initiation.</p></li>
<li><p>Suggest processing by parallel low-level visual system.</p></li>
</ul>
<div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Popout</h2>

<img data-src="figs/popout.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Some features are not pre-attentive</h2>

<img data-src="figs/not-preattentive.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Tasks requiring the use of multiple channels are (most of the time) not preattentive</h2>

<img data-src="figs/not-preattentive2.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Separability</h2>
<ul>
<li>Amount of interference between channels</li>
</ul>

<img data-src="figs/color-and-shape.jpg" class="r-stretch"><div class="footer">
<p>Slides based on material from Prof.&nbsp;Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Relative vs Absolute</h2>

<img data-src="figs/absolute-vs-relative.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Color</h2>

<img data-src="figs/animal-colors.jpg" class="r-stretch"><p>Vasas et al, PLOS Biology, 2024</p>
<div class="footer">
<p>Image from <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002444">link</a></p>
</div>
</section>
<section class="slide level2">
<h2>Visible Spectrum</h2>

<img data-src="figs/visiblespectrum.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Light</h2>
<ul>
<li><p>Visible range: 390-700nm</p></li>
<li><p>Luminance has a large dynamic range:</p>
<p>– 0.00003 – Moonless overcast night sky</p>
<p>– 30 – Sky on overcast day</p>
<p>– 3000 – Sky on clear day</p>
<p>– 16,000 – Snowy ground in full sunlight</p></li>
<li><p>Colors result from spectral curves</p>
<p>– dominant wavelength, hue</p>
<p>– brightness, lightness</p>
<p>– purity, saturation</p></li>
</ul>
</section>
<section class="slide level2">
<h2>Physiology of the Eye</h2>

<img data-src="figs/physiology-eye.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>The Retina</h2>

<img data-src="figs/retina.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Photoreceptors</h2>
<ul>
<li>Discrete sensors that measure energy – Adaptation</li>
<li>Rods
<ul>
<li>active at low light levels (scotopic vision)</li>
<li>only one wavelength-sensitivity function</li>
</ul></li>
<li>Cones
<ul>
<li>active at normal light levels (photoptic)</li>
<li>three types: sensitivity functions with different peaks</li>
</ul></li>
</ul>
</section>
<section class="slide level2">
<h2>Cone Sensitivity</h2>

<img data-src="figs/cones-spectral-sensitity.jpg" class="r-stretch"><div class="footer">
<p>Image from <a href="https://wrfranklin.org/Teaching/graphics-f2019/files/stone_colors.pdf">link</a></p>
</div>
</section>
<section class="slide level2">
<h2>Density of Cones</h2>

<img data-src="figs/cones-density.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Cones and Rods</h2>

<img data-src="figs/cones-and-rods-sensitivity.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Color Stimulus</h2>

<img data-src="figs/color-stimulus.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Color Matching Experiments</h2>

<img data-src="figs/color-matching-experiments.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Color in Visualization</h2>
<ul>
<li><p>Trichromacy: Humans perceive colors according to three channels</p></li>
<li><p>Most usable and useful way to describe colors (especially for visualization):</p>
<ul>
<li>Hue, Saturation, Luminance</li>
</ul></li>
</ul>
<div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>How do we use color in visualization?</h2>
<ul>
<li><p>Quantify</p></li>
<li><p>Label</p></li>
</ul>
<div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Quantify</h2>

<img data-src="figs/color-quantify.jpg" class="r-stretch"><div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Label</h2>

<img data-src="figs/color-label.jpg" class="r-stretch"><div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Quantitative Color Scales</h2>
<ul>
<li>Desired Properties of Quantitative Color Scale:
<ul>
<li>Uniformity (value difference = perceived difference)</li>
<li>Discriminability (as many distinct values as possible)</li>
</ul></li>
</ul>
<div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Quantitative Color Scales</h2>
<ul>
<li>Desired Properties of Quantitative Color Scale:
<ul>
<li>Uniformity (value difference = perceived difference)</li>
<li>Discriminability (as many distinct values as possible)</li>
</ul></li>
</ul>
<div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Single Hue Sequential Scales</h2>
<ul>
<li>Choose one hue</li>
<li>Map value to luminance</li>
</ul>

<img data-src="figs/single-hue-color-scale.jpg" class="r-stretch"><div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Categorical Color Scales</h2>
<ul>
<li>Properties:
<ul>
<li>Uniformity (uniform saliency / nothing stands out)</li>
<li>Discriminability (as many distinct values as possible)</li>
</ul>
<img data-src="figs/categorical-color-scale.jpg"></li>
</ul>
<div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Categorical Color Scales</h2>
<ul>
<li><p>How many distinct values can one perceive?</p></li>
<li><p>how many can you use in a visualization?</p></li>
<li><p>Estimates are between 5-10 distinct codes.</p></li>
<li><p>Healey, Christopher G. “Choosing effective colours for data visualization.” Proceedings of IEEE Visualization’96, 1996.</p></li>
</ul>
<div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Diverging Color Scales</h2>
<ul>
<li>Sometime useful/necessary to distinguish values above and below a threshold.</li>
</ul>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/election-results-continous-colormap.jpg"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="figs/election-results-divergent-colormap.jpg"></p>
</div></div>
<p>Created using these data: <a href="https://github.com/tonmcg/County_Level_Election_Results_12-16">link</a></p>
<div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Color Blindness</h2>
<ul>
<li>Missing or defective photoreceptors:
<ul>
<li>10% male and 1% female have some color deficiencies</li>
</ul></li>
</ul>

<img data-src="figs/color-blindness.jpg" class="r-stretch"><p>Oliveira, Manuel. “Towards More Accessible Visualizations for Color-Vision-Deficient Individuals.” Comput. Sci. Eng., 2013.</p>
<div class="footer">
<p>Material from Enrico Bertini</p>
</div>
</section>
<section class="slide level2">
<h2>Today’s Class</h2>
<ul>
<li>Model Interpretation and Explanation</li>
<li>White-box Approaches and Visualizations</li>
<li>Related Research in VIS &amp; AI</li>
</ul>
</section>
<section class="slide level2">
<h2>Today’s Class</h2>
<ul>
<li>Model Interpretation and Explanation</li>
<li><span style="color: grey;">White-box Approaches and Visualizations</span></li>
<li><span style="color: grey;">Related Research in VIS &amp; AI</span></li>
</ul>
</section>
<section class="slide level2">
<h2>Why Model Interpretation &amp; Explanation?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="./figures/paper1.png"></p>
</div><div class="column" style="width:50%;">
<ul>
<li>Model Validation and Improvement</li>
<li>Decision Making and Knowledge Discovery</li>
<li>Gain Confidence and Obtain Trust</li>
</ul>
</div></div>
</section>
<section class="slide level2">
<h2>Machine-learning-assisted materials discovery using failed experiments</h2>
<div class="columns">
<div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./figures/svm.png"></p>
<figcaption>SVM derived decision tree</figcaption>
</figure>
</div>
</div><div class="column" style="width:60%;">
<ul>
<li>Researchers firstly built a database of chemistry experiments (new material).</li>
<li>Then they train an SVM to predict whether a new chemistry experiment will be successful.</li>
<li>Then they train a surrogate DT to explain the model to learn more about the experiment.</li>
</ul>
</div></div>
</section>
<section class="slide level2">
<h2>Why Model Interpretation &amp; Explanation?</h2>
<div class="columns">
<div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./figures/paper2.png"></p>
<figcaption>https://arxiv.org/abs/1702.08608</figcaption>
</figure>
</div>
</div><div class="column" style="width:60%;">
<ul>
<li>Fairness</li>
<li>Privacy</li>
<li>Reliability or Robustness</li>
<li>Causality</li>
<li>Trust</li>
</ul>
</div></div>
</section>
<section class="slide level2">
<h2>How Do We Interpret Model Behavior?</h2>
<p>Methods for machine learning model interpretation can be classified according to various criteria.</p>
<ul>
<li><p><strong>White-box / Intrinsic interpretability</strong>: Machine learning models that are considered interpretable due to their simple structure, such as short decision trees or sparse linear models. Interpretability is gained by explaining the internal structure of the model.</p></li>
<li><p><strong>Black-box / Post-hoc interpretability</strong>: Machine learning models that are hard to gain a comprehensive understanding of their inner working (e.g., deep neural networks) are considered black boxes. Interpretability is gained by explaining the model behavior after training.</p></li>
</ul>
<p><a href="https://christophm.github.io/interpretable-ml-book/taxonomy-of-interpretability-methods.html">Taxonomy of Interpretability Methods</a></p>
</section>
<section class="slide level2">
<h2>Today’s Class</h2>
<ul>
<li><span style="color: grey;">Model Interpretation and Explanation</span></li>
<li>White-box Approaches and Visualizations</li>
<li><span style="color: grey;">Related Research in VIS &amp; AI</span></li>
</ul>
</section>
<section class="slide level2">
<h2>White-box Models</h2>
<p>We discuss the following models that are intrinsically interpretable: - Linear Regression - Generalized Additive Models (GAM) - Tree-based Models - Decision Rules</p>
</section>
<section class="slide level2">
<h2>Linear Regression</h2>
<p>Linear models can be used to model the dependence of a regression target y on some features x in a format as below: <span class="math display">\[\begin{equation}
y = \beta_0 + \beta_1 x_1 + \ldots + \beta_n x_n + \varepsilon\end{equation}\]</span></p>
<p>The predicted target <span class="math inline">\(y\)</span> is a linear combination of the weighted features <span class="math inline">\(\beta_i x_i\)</span>. The estimated linear equation is a hyperplane in the feature/target space (a simple line in the case of a single feature).</p>
<p>The weights specify the slope (gradient) of the hyperplane in each direction.</p>
</section>
<section class="slide level2">
<h2>Linear Regression</h2>

<img data-src="./figures/illustration1.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Linear Regression: An Example of Housing Price</h2>

<img data-src="./figures/paper3.png" class="r-stretch"><p>How do you interpret the influence of each property on the prediction of housing price?</p>
</section>
<section class="slide level2">
<h2>Evaluation of Linear Regression Model</h2>
<h3>R Square</h3>
<p><span class="math inline">\(R^2\)</span> (R-squared) <span class="math display">\[\begin{equation}
R^2 = 1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2}
\end{equation}\]</span></p>
<p>Mean Square Error (MSE)/Root Mean Square Error (RMSE)</p>
<p><span class="math display">\[\begin{equation}
MSE = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2
\end{equation}\]</span></p>
<p>Mean Absolute Error (MAE)</p>
<p><span class="math display">\[\begin{equation}
MAE = \frac{1}{N} \sum_{i=1}^{N} |y_i - \hat{y}_i|
\end{equation}\]</span></p>
</section>
<section class="slide level2">
<h2>Visual Analytics (VA) Systems for Linear Regression</h2>
<div class="columns">
<div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./figures/paper4.png"></p>
<figcaption>https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6634169</figcaption>
</figure>
</div>
</div><div class="column" style="width:60%;">
<p>There is a trade-off between model complexity (number of features) and accuracy.</p>
<p>This VA system helps model building (feature ranking) and model validation.</p>
</div></div>
</section>
<section class="slide level2">
<h2>Pros and Cons of Linear Models</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Pros:</p>
</div><div class="column" style="width:50%;">
<p>Cons:</p>
</div></div>
</section>
<section class="slide level2">
<h2>Pros and Cons of Linear Models</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Pros:</p>
<p>Easily interpretable</p>
<p>Statistical guarantees on inference (if assumptions are satisfied)</p>
<p>No hyperparameters (analytical solution)</p>
</div><div class="column" style="width:50%;">
<p>Cons:</p>
<p><span class="math inline">\(X\)</span>’s relationship with <span class="math inline">\(Y\)</span> can be non-linear. In these cases, linear regression may not provide good results.</p>
<p>If you don’t satisfy certain assumptions (namely normal distribution of residuals and homoscedasticity), then inference can be incorrect.</p>
</div></div>
</section>
<section class="slide level2">
<h2>Limitations of Linear Models</h2>
<ul>
<li>Features are assumed to follow Gaussian distribution</li>
<li>No interactions between features</li>
</ul>
<p>What if your dataset does not follow the assumptions?</p>
</section>
<section class="slide level2">
<h2>Generalized Additive Models (GAMs)</h2>
<p>Generalized additive models extend standard linear models by allowing non-linear functions of each of the variables. <span class="math display">\[\begin{equation}
y_i = \beta_0 + \sum_{j=1}^{p} f_j(x_{ij}) + \varepsilon_i \\
= \beta_0 + f_1(x_{i1}) + f_2(x_{i2}) + \dots + f_p(x_{ip}) + \varepsilon_i

\end{equation}\]</span></p>
</section>
<section class="slide level2">
<h2>Generalized Additive Models (GAMs): An Example</h2>
<p><span class="math display">\[\begin{equation}
Wage = f(year, age, education) = b_0 + f_1(year) + f_2(age) + f_3(education)
\end{equation}\]</span> <img data-src="./figures/exp1.png"></p>
</section>
<section class="slide level2">
<h2>Training GAMs (Backfitting)</h2>

<img data-src="./figures/algo1.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Generalized Additive Models (GAMs): Pros and Cons</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Pros:</p>
<p>GAMs allow us to fit a non-linear <span class="math inline">\(f_j\)</span> to each <span class="math inline">\(X_j\)</span> , so that we can model non-linear relationships easily.</p>
<p>The non-linear fits can potentially lead to better predictions.</p>
<p>Because the model is additive, we can examine the effect of each <span class="math inline">\(X_j\)</span> on <span class="math inline">\(Y\)</span> for each observation. This is useful for visualization.</p>
</div><div class="column" style="width:50%;">
<p>Cons:</p>
<p>GAMs are restricted to be additive. With many variables, important interactions can be missed or computationally infeasible to find.</p>
</div></div>
</section>
<section class="slide level2">
<h2>Explainable Boosting Machines</h2>
<div class="columns">
<div class="column" style="width:65%;">
<p><span class="math display">\[\begin{equation}
g(\mathbb{E}[y]) = \beta_0 + \sum f_j(x_j)

\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
g(\mathbb{E}[y]) = \beta_0 + \sum f_j(x_j) + \sum f_{ij}(x_i, x_j)

\end{equation}\]</span></p>
</div><div class="column" style="width:35%;">
<p>However, as with linear regression, we can manually add interaction terms to the GAM model by including additional predictors of the form <span class="math inline">\(X_j \times X_k\)</span>. In addition we can add low-dimensional interaction functions of the form <span class="math inline">\(f_{jk}(X_j , X_k)\)</span> into the model.</p>
</div></div>
</section>
<section class="slide level2">
<h2>Explainable Boosting Machines</h2>
<div class="columns">
<div class="column" style="width:65%;">
<p><span class="math display">\[\begin{equation}
g(\mathbb{E}[y]) = \beta_0 + \sum f_j(x_j)

\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
g(\mathbb{E}[y]) = \beta_0 + \sum f_j(x_j) + \sum f_{ij}(x_i, x_j)

\end{equation}\]</span></p>
</div><div class="column" style="width:35%;">
<p>What if we have a lot of interactions? How do we choose our interactions?</p>
</div></div>
</section>
<section class="slide level2">
<h2>Explainable Boosting Machines</h2>
<!-- ![]{./figures/exp2.png} -->
<p><iframe data-external="1" src="https://www.youtube.com/embed/MREiHgHgl0k" width="1080" height="720" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> <!-- ![](./figures/exp2.png) --></p>
</section>
<section class="slide level2">
<h2>Visualizing EBMs (or GAMs)</h2>

<img data-src="./figures/exp3.png" class="r-stretch quarto-figure-center"><p class="caption">Partial dependency plot</p></section>
<section class="slide level2">
<h2>Visualizing EBMs (or GAMs)</h2>

<img data-src="./figures/exp4.png" class="r-stretch quarto-figure-center"><p class="caption">Partial dependency plot</p></section>
<section class="slide level2">
<h2>Visualizing EBMs (or GAMs)</h2>

<img data-src="./figures/exp5.png" class="r-stretch quarto-figure-center"><p class="caption">Partial dependency plot</p></section>
<section class="slide level2">
<h2>Visualizing EBMs (or GAMs)</h2>

<img data-src="./figures/exp6.png" class="r-stretch quarto-figure-center"><p class="caption">Partial dependency plot</p></section>
<section class="slide level2">
<h2>Visual Analytics (VA) Systems Using GAMs</h2>

<img data-src="./figures/paper5.png" class="r-stretch quarto-figure-center"><p class="caption"><a href="https://www.microsoft.com/en-us/research/publication/gamut-a-design-probe-to-understand-howdata-scientists-understand-machine-learning-models/">Individual observation feature contributions</a></p></section>
<section class="slide level2">
<h2>Visual Analytics (VA) Systems Using GAMs</h2>

<img data-src="./figures/paper6.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Visual Analytics (VA) Systems Using GAMs</h2>

<img data-src="./figures/paper7.png" class="r-stretch quarto-figure-center"><p class="caption">GAM Changer</p><p>https://arxiv.org/pdf/2112.03245.pdf https://github.com/interpretml/gam-changer</p>
</section>
<section class="slide level2">
<h2>Practice 1</h2>
<p>Notebook: https://colab.research.google.com/drive/1nKE6WIApebHi67yfhH6k5mZN86evLZOM?usp=sharing</p>
<p>Some other libraries for PDP visualization: https://scikit-learn.org/stable/modules/partial_dependence.html https://interpret.ml/docs/pdp.html</p>
</section>
<section class="slide level2">
<h2>BREAK</h2>
</section>
<section class="slide level2">
<h2>Tree-based Models: Example</h2>

<img data-src="./figures/paper8.png" class="r-stretch quarto-figure-center"><p class="caption">A decision tree of diabetes diagnosis</p></section>
<section class="slide level2">
<h2>Visualization of Trees</h2>
<p>https://treevis.net/ provides a gallery of tree visualization. These trees are used to visualize hierarchical structures, but not just tree-based machine learning models. <img data-src="./figures/paper9.png"></p>
</section>
<section class="slide level2">
<h2>VA Systems Using Tree-based Models</h2>
<div class="columns">
<div class="column" style="width:65%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./figures/paper10.png"></p>
<figcaption>BaobabView</figcaption>
</figure>
</div>
</div><div class="column" style="width:35%;">
<p>It shows the flow of different class, and the class distribution in along the feature values.</p>
</div></div>
</section>
<section class="slide level2">
<h2>VA Systems Using Tree-based Models</h2>

<img data-src="./figures/paper11.png" class="r-stretch quarto-figure-center"><p class="caption">iForest</p></section>
<section class="slide level2">
<h2>Decision Rules: Different Structures</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="./figures/paper12.png" alt="Rule List: If-then-else structure."> Clearly see how the decision is made and which rule is more important.</p>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./figures/paper13.png"></p>
<figcaption>Rule Set: A set of if-then rules.</figcaption>
</figure>
</div>
<p>The final decision is made based on a voting mechanism.</p>
<p>A recent user study shows that “if-then structure without any connecting else statements enables users to easily reason about the decision boundaries of classes.”</p>
</div></div>
</section>
<section class="slide level2">
<h2>Decision Rules: Different Structures</h2>
<p>Disjunctive normal form (DNF, OR-of-ANDs) Conjunctive normal form (CNF, AND-of-ORs)</p>

<img data-src="./figures/paper14.png" class="r-stretch quarto-figure-center"><p class="caption">What form does this rule set follow?</p></section>
<section class="slide level2">
<h2>Decision Rules: Visual Factors Influence Rule Understanding</h2>
<div class="columns">
<div class="column" style="width:65%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./figures/paper15.png"></p>
<figcaption>Paper: https://arxiv.org/abs/2109.09160</figcaption>
</figure>
</div>
</div><div class="column" style="width:35%;">
<p>Can different visualizations of rules lead to different level of understanding of rules?</p>
<p>If so, what are the visual factors influence understanding and how they play a role in rule understanding?</p>
</div></div>
</section>
<section class="slide level2">
<h2>Evaluation of Rules</h2>
<p>Given a rule below:</p>
<p>If <span class="math inline">\(X\)</span>, then class <span class="math inline">\(Y\)</span>.</p>
<p>Support / Coverage of a rule:</p>
<p><span class="math display">\[\begin{equation}
\text{Support} = \frac{\text{number of instances that match the conditions in } X}{\text{total number of instances}}
\end{equation}\]</span></p>
<p>Confidence / Accuracy of a rule:</p>
<p><span class="math display">\[\begin{equation}
\text{Confidence} = \frac{\text{number of instances that match conditions in } X \text{ and belong to class } Y}{\text{number of instances that match conditions in } X}
\end{equation}\]</span></p>
</section>
<section class="slide level2">
<h2>Global Surrogate</h2>
<p>Imagine that we have a black-box model (too complex to understand the internal structure), can we use white-box models to help us understand the model behavior of the black-box model? <img data-src="./figures/illustration2.png"></p>
</section>
<section class="slide level2">
<h2>Global Surrogate</h2>
<p>Open the black box by understanding a “surrogate model” that approximate the behavior of the original black-box model. <img data-src="./figures/illustration3.png"></p>
</section>
<section class="slide level2">
<h2>However…</h2>
<p>What you want:</p>
<p><img data-src="./figures/illustration4.png" width="540"></p>
<p>What you get:</p>
<p><img data-src="./figures/illustration5.png"></p>
</section>
<section class="slide level2">
<h2>VA System for Rule List</h2>

<img data-src="./figures/paper16.png" class="r-stretch quarto-figure-center"><p class="caption">RuleMatrix</p></section>
<section class="slide level2">
<h2>VA Systems for Rules in Random Forest</h2>

<img data-src="./figures/paper17.png" class="r-stretch quarto-figure-center"><p class="caption">Explainable Matrix</p></section>
<section class="slide level2">
<h2>Other white-box models?</h2>
<ul>
<li>Naive Bayes</li>
<li>K-nearest neighbors</li>
<li>etc.</li>
</ul>
</section>
<section class="slide level2">
<h2>Practice 2</h2>
<p>Notebook: https://colab.research.google.com/drive/12LV2Z_1BbP3efACYp2QxzsPaOrIn8a8l?usp=sharing</p>
</section>
<section class="slide level2">
<h2>Today’s Class</h2>
<ul>
<li><span style="color: grey;">Model Interpretation and Explanation</span></li>
<li><span style="color: grey;">White-box Approaches and Visualizations</span></li>
<li>Related Research in VIS &amp; AI</li>
</ul>
</section>
<section class="slide level2">
<h2>Manipulating and Measuring Model Interpretability</h2>

<img data-src="./figures/paper18.png" class="r-stretch"><p>https://arxiv.org/abs/1802.07810</p>
</section>
<section class="slide level2">
<h2>Stop explaining black box machine learning models for high stakes decisions</h2>

<img data-src="./figures/paper19.png" class="r-stretch"><p>https://www.nature.com/articles/s42256-019-0048-x</p>
</section>
<section class="slide level2">
<h2>Slice Finder: Automated Data Slicing for Model Validation</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="./figures/paper20.png"></p>
</div><div class="column" style="width:50%;">
<p>How about we use whether the model prediction is wrong or not to train a “surrogate tree”?</p>
</div></div>
<p>https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8731353</p>
</section>
<section class="slide level2">
<h2>Toolkits</h2>
<p>InterpretML: https://github.com/interpretml/interpret</p>
</section>
<section>
<section class="title-slide slide level1 center">
<h1>Black Box Model Assessment</h1>

</section>
<section class="slide level2">
<h2>Agenda</h2>
<p><br>
</p>
<h3>Goal: Study Model Agnostic Interpretability Methods. These should help to explain any type of ML Models.</h3>
<ol type="1">
<li><p>Partial Dependence Plot (PDP)</p></li>
<li><p>Local Interpretable Model-agnostic Explanations (LIME)</p></li>
<li><p>SHAP (SHapley Additive exPlanations)</p></li>
</ol>
<p>Examples and materials from Molnar’s book: https://christophm.github.io/interpretable-ml-book/</p>
</section>
<section class="slide level2">
<h2>Bike Rentals (Regression)</h2>
<div class="r-fit-text">
<p>This dataset contains daily counts of rented bicycles from the bicycle rental company Capital-Bikeshare in Washington D.C., along with weather and seasonal information. The goal is to predict how many bikes will be rented depending on the weather and the day. The data can be downloaded from the UCI Machine Learning Repository.</p>
<p>Here is the list of features used in Molnar’s book:</p>
<ul>
<li>Count of bicycles including both casual and registered users. The count is used as the target in the regression task.</li>
<li>The season, either spring, summer, fall or winter.</li>
<li>Indicator whether the day was a holiday or not.</li>
<li>The year, either 2011 or 2012.</li>
<li>Number of days since the 01.01.2011 (the first day in the dataset). This feature was introduced to take account of the trend over time.</li>
<li>Indicator whether the day was a working day or weekend.</li>
<li>The weather situation on that day. One of: clear, few clouds, partly cloudy, cloudy mist + clouds, mist + broken clouds, mist + few clouds, mist light snow, light rain + thunderstorm + scattered clouds, light rain + scattered clouds heavy rain + ice pallets + thunderstorm + mist, snow + mist</li>
<li>Temperature in degrees Celsius.</li>
<li>Relative humidity in percent (0 to 100).</li>
<li>Wind speed in km per hour.</li>
</ul>
</div>
</section>
<section class="slide level2">
<h2>Partial Dependence Plot (PDP)</h2>
<p>Shows the marginal effect one or two features have on the predicted outcome of a machine learning model (J. H. Friedman 2001).</p>

<img data-src="figs/bike-use-temperature.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Partial Dependence Plot (PDP)</h2>
<p>High level idea: marginalizing the machine learning model output over the distributions of the all other features to show the relationship between the feature we are interested in and the predicted outcome.</p>
<div class="r-stack">
<p><img data-src="figs/pdp-feature1.jpg" class="fragment" width="950" height="450"></p>
<p><img data-src="figs/pdp-feature2.jpg" class="fragment" width="950" height="450"></p>
<p><img data-src="figs/pdp-feature3.jpg" class="fragment" width="950" height="450"></p>
<p><img data-src="figs/pdp-feature4.jpg" class="fragment" width="950" height="450"></p>
<p><img data-src="figs/pdp-feature5.jpg" class="fragment" width="950" height="450"></p>
<p><img data-src="figs/pdp-feature6.jpg" class="fragment" width="950" height="450"></p>
</div>
</section>
<section class="slide level2">
<h2>Partial Dependence Plot (PDP)</h2>
<div class="fragment">
<p><strong>Pros</strong></p>
<ul>
<li>Intuitive</li>
<li>Interpretation is clear</li>
<li>Easy to implement</li>
</ul>
</div>
<div class="fragment">
<p><strong>Cons</strong></p>
<ul>
<li>Assume independence among features</li>
<li>Can only show few features</li>
<li>Hidden heterogeneous effects from averaging</li>
</ul>
</div>
</section>
<section class="slide level2">
<h2>Local Interpretable Model-agnostic Explanations (LIME)</h2>
<p>Training local surrograte models to explain <em>individual</em> predictions</p>
<div class="columns">
<div class="column" style="width:60%;">
<p><img data-src="figs/lime-global-decision-boundaries.jpg"></p>
</div><div class="column" style="width:40%;">
<p><img data-src="figs/lime-paper.jpg"></p>
</div></div>
<p>https://arxiv.org/pdf/1602.04938.pdf</p>
</section>
<section class="slide level2">
<h2>Local Interpretable Model-agnostic Explanations (LIME)</h2>
<div class="r-fit-text">
<p>The idea is quite intuitive.</p>
<ul>
<li><p>First, forget about the training data and imagine you only have the black box model where you can input data points and get the predictions of the model. You can probe the box as often as you want. Your goal is to understand why the machine learning model made a certain prediction. LIME tests what happens to the predictions when you give variations of your data into the machine learning model.</p></li>
<li><p>LIME generates a new dataset consisting of perturbed samples and the corresponding predictions of the black box model.</p></li>
<li><p>On this new dataset LIME then trains an interpretable model, which is weighted by the proximity of the sampled instances to the instance of interest. The interpretable model can be anything from the interpretable models chapter, for example Lasso or a decision tree. The learned model should be a good approximation of the machine learning model predictions locally, but it does not have to be a good global approximation. This kind of accuracy is also called <em>local fidelity</em>.</p></li>
</ul>
</div>
<p>https://christophm.github.io/interpretable-ml-book/</p>
</section>
<section class="slide level2">
<h2>Local Interpretable Model-agnostic Explanations (LIME)</h2>

<img data-src="figs/lime-equations.jpg" class="r-stretch"><p>https://arxiv.org/pdf/1602.04938.pdf</p>
</section>
<section class="slide level2">
<h2>Local Interpretable Model-agnostic Explanations (LIME)</h2>
<h3>Algorithm</h3>
<ol type="1">
<li>Pick an input that you want an explanation for.</li>
<li>Sample the neighbors of the selected input (i.e.&nbsp;perturbation).</li>
<li>Train a linear classifier on the neighbors.</li>
<li>The weights on the linear classifier is the explanation.</li>
</ol>
</section>
<section class="slide level2">
<h2>Local Interpretable Model-agnostic Explanations (LIME)</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p><img data-src="figs/lime-random-forest-model.jpg"></p>
</div><div class="column" style="width:40%;">
<p>Random forest predictions given features x1 and x2.</p>
<p>Predicted classes: 1 (dark) or 0 (light).</p>
</div></div>
</section>
<section class="slide level2">
<h2>Local Interpretable Model-agnostic Explanations (LIME)</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p><img data-src="figs/lime-random-forest-sampling.jpg"></p>
</div><div class="column" style="width:40%;">
<p>Instance of interest (big yellow dot) and data sampled from a normal distribution (small dots).</p>
</div></div>
</section>
<section class="slide level2">
<h2>Local Interpretable Model-agnostic Explanations (LIME)</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p><img data-src="figs/lime-random-forest-weighting.jpg"></p>
</div><div class="column" style="width:40%;">
<p>Assign higher weight to points near the instance of interest. I.e., <span class="math inline">\(weight(p) = \sqrt{\frac{e^{-d^2}}{w^2}}\)</span> where <span class="math inline">\(d\)</span> is the distance between <span class="math inline">\(p\)</span> and the instantce of interest, and <span class="math inline">\(w\)</span> is the kernel width (self-defined).</p>
</div></div>
</section>
<section class="slide level2">
<h2>Local Interpretable Model-agnostic Explanations (LIME)</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p><img data-src="figs/lime-random-forest-line.jpg"></p>
</div><div class="column" style="width:40%;">
<p>Use both the samples and sample weights to train a linear classifier.</p>
<p>Signs of the grid show the classifications of the locally learned model from the weighted samples. The red line marks the decision boundary (P(class=1) = 0.5).</p>
<p>The official implementation uses a Ridge Classifier as the linear model for explanation.</p>
</div></div>
</section>
<section class="slide level2">
<h2>Local Interpretable Model-agnostic Explanations (LIME)</h2>
<div class="r-fit-text">
<div class="columns">
<div class="column" style="width:50%;">
<p>Let us look at a concrete example. We go back to the bike rental data and turn the prediction problem into a classification: After taking into account the trend that the bicycle rental has become more popular over time, we want to know on a certain day whether the number of bicycles rented will be above or below the trend line. You can also interpret “above” as being above the average number of bicycles, but adjusted for the trend.</p>
<p>First we train a random forest with 100 trees on the classification task. On what day will the number of rental bikes be above the trend-free average, based on weather and calendar information?</p>
<p>The explanations are created with 2 features. The results of the sparse local linear models trained for two instances with different predicted classes:</p>
</div><div class="column" style="width:50%;">
<p><img data-src="figs/lime-example-result.jpg"></p>
</div></div>
</div>
</section>
<section class="slide level2">
<h2>Local Interpretable Model-agnostic Explanations (LIME)</h2>
<div class="fragment">
<p><strong>Pros</strong></p>
<ul>
<li>Explanations are short (= selective) and possibly contrastive.
<ul>
<li>we can control the sparsity of weight coefficients in the regressions method.</li>
</ul></li>
<li>Very easy to use.</li>
</ul>
</div>
<div class="fragment">
<p><strong>Cons</strong></p>
<ul>
<li>Unstable results due to sampling.</li>
<li>Hard to weight similar neighbors in a high dimensional dataset.</li>
<li>Many parameters for data scientists to hide biases.</li>
</ul>
</div>
</section>
<section class="slide level2">
<h2>SHAP (SHapley Additive exPlanations)</h2>
<p>Examples and materials from Molnar’s new book: https://christophmolnar.com/books/shap/</p>
<div class="columns">
<div class="column" style="width:60%;">
<p><img data-src="figs/shap-example.jpg"></p>
</div><div class="column" style="width:40%;">
<p>SHAP (Lundberg and Lee 2017a) is a game-theory-inspired method created to explain predictions made by machine learning models. SHAP generates one value per input feature (also known as SHAP values) that indicates how the feature contributes to the prediction of the specified data point.</p>
</div></div>
</section>
<section class="slide level2">
<h2>A Short History of Shapley Values and SHAP</h2>
<ul>
<li>1953: The introduction of Shapley values in game theory (by Lloyd Shapley).</li>
<li>2010: The initial steps toward applying Shapley values in machine learning
<ul>
<li>original paper contained NO code!</li>
</ul></li>
<li>2017: The advent of SHAP (by Lundberg and Lee), a turning point in machine learning.</li>
</ul>
</section>
<section class="slide level2">
<h2>Theory of Shapley Values</h2>
<p>Who’s going to pay for that taxi?</p>
<p>Alice, Bob, and Charlie have dinner together and share a taxi ride home. The total cost is $51. The question is, how should they divide the costs fairly?</p>

<img data-src="figs/shap-taxi.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Theory of Shapley Values</h2>
<p>The <strong>marginal contribution</strong> of a player to a coalition is the value of the coali- tion with the player minus the value of the coalition without the player. In the taxi example, the value of a coalition is equal to the cost of the ride as detailed in the above table. Therefore, the marginal contribution of, for instance, Charlie to a taxi already containing Bob is the cost of the taxi with Bob and Charlie, minus the cost of the taxi with Bob alone.</p>
</section>
<section class="slide level2">
<h2>Theory of Shapley Values</h2>

<img data-src="figs/shap-marginal-contribution.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Theory of Shapley Values</h2>
<p>How to average these marginal contributions per passenger?</p>
<p>One way to answer this question is by considering all possible permutations of Alice, Bob, and Charlie. There are 3! = 3 * 2 * 1 = 6 possible permutations of passengers:</p>
<ul>
<li>Alice, Bob, Charlie</li>
<li>Alice, Charlie, Bob</li>
<li>Bob, Alice, Charlie</li>
<li>Charlie, Alice, Bob</li>
<li>Bob, Charlie, Alice</li>
<li>Charlie, Bob, Alice</li>
</ul>
<p>We can use these permutations to form coalitions, for example, for Alice.</p>
</section>
<section class="slide level2">
<h2>Theory of Shapley Values</h2>
<p>In two of these cases, Alice was added to an empty taxi, and in one case, she was added to a taxi with only Bob. By weighting the marginal contributions accordingly, we calculate the following weighted average marginal contribution for Alice, abbreviating Alice, Bob, and Charlie to A, B, and C:</p>

<img data-src="figs/shap-marginal-alice.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Theory of Shapley Values</h2>
<p>for Bob:</p>
<p><img data-src="figs/shap-marginal-bob.jpg"></p>
<p>for Charlie:</p>
<p><img data-src="figs/shap-marginal-charlie.jpg"></p>
</section>
<section class="slide level2">
<h2>Calculating Shapley values</h2>

<img data-src="figs/shap-general-formation.jpg" class="r-stretch"><p><strong>The Shapley value is the weighted average of a player’s marginal contribu- tions to all possible coalitions.</strong></p>
</section>
<section class="slide level2">
<h2>The axioms behind Shapley values</h2>
<ul>
<li><p>Efficiency: The sum of the contributions must precisely add up to the payout.</p></li>
<li><p>Symmetry: If two players are identical, they should receive equal contributions.</p></li>
<li><p>Dummy or Null Player: The value of a player who doesn’t contribute to any coalition is zero.</p></li>
<li><p>Additivity: In a game with two value functions, the Shapley values for the sum can be expressed as the sum of the Shapley values.</p></li>
</ul>
<p><strong>These four axioms ensure the uniqueness of the Shapley values.</strong></p>
</section>
<section class="slide level2">
<h2>From Shapley Values to SHAP</h2>
<p>Consider the following scenario: You have trained a machine learning model <span class="math inline">\(f\)</span> to predict apartment prices.</p>

<img data-src="figs/shap-apartment-example.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>From Shapley Values to SHAP</h2>
<p>We want to evaluate the effort of cat-banned</p>

<img data-src="figs/shap-cat-banned.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>From Shapley Values to SHAP</h2>
<p>We want to evaluate the effort of cat-banned</p>

<img data-src="figs/shap-cat-banned-2.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Interpreting SHAP values</h2>
<p>The Shapley value can be misinterpreted. The Shapley value of a feature value is not the difference of the predicted value after removing the feature from the model training. The interpretation of the Shapley value is: <strong>Given the current set of feature values, the contribution of a feature value to the difference between the actual prediction and the mean prediction is the estimated Shapley value.</strong></p>
<p>The Shapley value is the wrong explanation method if you seek sparse explanations (explanations that contain few features). Explanations created with the Shapley value method <strong>always use all the features.</strong> Humans prefer selective explanations, such as those produced by LIME. LIME might be the better choice for explanations lay-persons have to deal with.</p>
<p>(From Molnar’s book)</p>
</section>
<section class="slide level2">
<h2>SHAP (SHapley Additive exPlanations)</h2>
<div class="fragment">
<p><strong>Pros</strong></p>
<ul>
<li><p>Fairly distributed feature importance to a prediction</p></li>
<li><p>Contrastive explanations (can compare an instance to a subset or even to a single data point)</p></li>
<li><p>Solid theory</p></li>
</ul>
</div>
<div class="fragment">
<p><strong>Cons</strong></p>
<ul>
<li>A lot of computing time</li>
<li>Not sparse explanations (every feature is important)</li>
</ul>
</div>
</section>
<section class="slide level2">
<h2>SHAP (SHapley Additive exPlanations)</h2>

<img data-src="figs/shap-figure-waterfall.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>SHAP limitations</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/shap-problems.jpg"></p>
<p>http://proceedings.mlr.press/v119/kumar20e/kumar20e.pdf</p>
</div><div class="column" style="width:40%;">

</div></div>
</section>
<section class="slide level2">
<h2>Deep Learning</h2>
<ul>
<li>We will start by reviewing concepts of Deep Learning.</li>
</ul>
</section>
<section class="slide level2">
<h2>Deep Learning</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Understanding Deep Learning by Simon J.D. Prince. Published by MIT Press, 2023.</p>
<p>https://udlbook.github.io/udlbook</p>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/UDLCoverSmall.jpg" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div></div>
</section>
<section class="slide level2">
<h2>Deep Learning Terminology</h2>
<ul>
<li><p>Inference: <span class="math inline">\(y = f[x, \Phi]\)</span></p></li>
<li><p><span class="math inline">\(y\)</span>: prediction</p></li>
<li><p><span class="math inline">\(x\)</span>: input</p></li>
<li><p><span class="math inline">\(\Phi\)</span>: model parameters</p></li>
<li><p>We “learn” the parameters from pairs of “training data” <span class="math inline">\(\{x_i, y_i\}\)</span></p></li>
<li><p>We quantify the accuracy by using a (scalar) loss function <span class="math inline">\(L[\Phi]\)</span>. The smaller the loss, the better our model “fits” the data.</p></li>
<li><p>To check the “generalization” of the model, we run the model on “test data”, which is separate from the training data.</p></li>
</ul>
</section>
<section class="slide level2">
<h2>1-D linear regression model</h2>
<ul>
<li><span class="math inline">\(y = f[x, \Phi] = \Phi_0 + \Phi_1 x\)</span></li>
</ul>

<img data-src="figs/UDLChap2PDF/SupervisedLinear.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>1-D linear regression model: Loss</h2>

<img data-src="figs/UDLChap2PDF/SupervisedLinearFitError.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>1-D linear regression model: Loss</h2>

<img data-src="figs/UDLChap2PDF/SupervisedLinearFitError.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>1-D linear regression model: Loss Surface</h2>

<img data-src="figs/UDLChap2PDF/SupervisedSurface.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>1-D linear regression model: Optimization</h2>

<img data-src="figs/UDLChap2PDF/SupervisedOpt.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>Shallow neural networks</h2>
<ul>
<li><p><span class="math inline">\(y = f[x, \Phi] = \Phi_0 \\
+ \Phi_1 a[ \Theta_{10} + \Theta_{11} x] \\
+ \Phi_2 a[ \Theta_{20} + \Theta_{21} x] \\
+ \Phi_3 a[ \Theta_{30} + \Theta_{31} x]\)</span></p></li>
<li><p>We now have 10 parameters</p></li>
<li><p>And also, an “activation” function <span class="math inline">\(a[]\)</span></p></li>
</ul>
</section>
<section class="slide level2">
<h2>Shallow neural networks: Activation function ReLU</h2>

<img data-src="figs/UDLChap3PDF/ShallowReLU.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>Shallow neural networks: Neural network intuition</h2>

<img data-src="figs/UDLChap3PDF/ShallowFunctions.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>Shallow neural networks: Neural network intuition</h2>

<img data-src="figs/UDLChap3PDF/ShallowBuildUp.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>Shallow neural networks: Neural network intuition</h2>

<img data-src="figs/UDLChap3PDF/ShallowNet.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>Shallow neural networks: Universal Approximation Theorem</h2>

<img data-src="figs/UDLChap3PDF/ShallowApproximate.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>Shallow neural networks: Terminology</h2>
<ul>
<li>Neural networks is composed of “layers”</li>
<li>“input” layer, “hidden” layers, “output layer”</li>
<li>Hidden units are called “neurons”</li>
<li>As data passes through, the values are called “pre-activation” and “activations”</li>
</ul>
</section>
<section class="slide level2">
<h2>Deep neural networks: Composing multiple networks</h2>

<img data-src="figs/UDLChap4PDF/DeepConcat.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>Deep neural networks: Folding Input Space</h2>

<img data-src="figs/UDLChap4PDF/DeepFold.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>Deep neural networks: Two hidden layers</h2>

<img data-src="figs/UDLChap4PDF/DeepTwoLayer.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>Deep neural networks: Multiple hidden layers</h2>

<img data-src="figs/UDLChap4PDF/DeepKLayer.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>https://playground.tensorflow.org</h2>

<img data-src="figs/tensorflow-playground.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>https://poloclub.github.io/cnn-explainer/</h2>

<img data-src="figs/cnnexplainer.jpg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>Further References</h2>
<ul>
<li><p>https://distill.pub/2020/grand-tour/</p></li>
<li><p>http://projector.tensorflow.org/</p></li>
<li><p>https://ml4a.github.io/ml4a/looking_inside_neural_nets/</p></li>
</ul>
</section>
<section class="slide level2">
<h2>Graph Layout using force based approach</h2>
<p><a href="https://www.youtube.com/watch?v=_Oidv5M-fuw">video link</a></p>
</section>
<section class="slide level2">
<h2>SNE and t-SNE</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/sne.jpg"></p>
</div><div class="column" style="width:40%;">
<p><img data-src="figs/tsne.jpg"></p>
</div></div>
<p>HERE is an excellent talk by t-SNE creator: <a href="https://www.youtube.com/watch?v=RJVL80Gg3lA&amp;list=UUtXKDgv1AVoG88PLl8nGXmw">video link</a></p>
<!-- ##

 -->
</section>
<section class="slide level2">
<h2>Digression: Point Set Surfaces</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/pss.jpg"></p>
</div><div class="column" style="width:40%;">
<p><img data-src="figs/pss-h.jpg"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Wattenberg, Viégas, and Johnson, 2016</h2>

<img data-src="figs/using-tsne.jpg" class="r-stretch"><p>https://distill.pub/2016/misread-tsne/</p>
</section>
<section class="slide level2">
<h2>t-SNE</h2>
<ul>
<li><p>Wattenberg et al writes “A popular method for exploring high-dimensional data is something called t-SNE… it has an almost magical ability to create compelling two-dimensonal “maps” from data with hundreds or even thousands of dimensions. Although impressive, these images can be tempting to misread.”</p></li>
<li><p>Wattenberg: “The algorithm is <strong>non-linear</strong> and adapts to the underlying data, performing <strong>different transformations on different regions</strong>. Those differences can be a major source of confusion.”</p></li>
<li><p>Watternberg: “A second feature of t-SNE is a tuneable parameter, <strong>“perplexity,”</strong> which says (loosely) how to balance attention between local and global aspects of your data. The parameter is, in a sense, a guess about the number of close neighbors each point has. The perplexity value has a complex effect on the resulting pictures.”</p></li>
</ul>
</section>
<section class="slide level2">
<h2>t-SNE</h2>
<ul>
<li>“Those hyperparameters really matter”</li>
</ul>

<img data-src="figs/tsneperplexity.jpg" class="r-stretch"><ul>
<li>“The image for perplexity 100, with merged clusters, illustrates a pitfall: for the algorithm to operate properly, the perplexity really should be smaller than the number of points.”</li>
</ul>
</section>
<section class="slide level2">
<h2>t-SNE</h2>
<ul>
<li>“Each of the plots above was made with 5,000 iterations with a learning rate (often called “epsilon”) of 10, and had reached a point of stability by step 5,000. How much of a difference do those values make?”</li>
</ul>

<img data-src="figs/tsnesteps.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>t-SNE</h2>
<ul>
<li>“Cluster sizes in a t-SNE plot mean nothing”</li>
</ul>

<img data-src="figs/tsneclustersizes.jpg" class="r-stretch"><ul>
<li><p>“By size we mean bounding box measurements, not number of points.”</p></li>
<li><p>“The t-SNE algorithm adapts its notion of “distance” to regional density variations in the data set. As a result, it naturally expands dense clusters, and contracts sparse ones, evening out cluster sizes.”</p></li>
</ul>
</section>
<section class="slide level2">
<h2>t-SNE</h2>
<ul>
<li><p>“Distances between clusters might not mean anything”</p></li>
<li><p>“The next diagrams show three Gaussians of 50 points each, one pair being 5 times as far apart as another pair.”</p></li>
</ul>

<img data-src="figs/tsneclusterdistances.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>t-SNE</h2>
<ul>
<li><p>“Random noise doesn’t always look random.”</p></li>
<li><p>“The next diagrams show genuinely random data, 500 points drawn from a unit Gaussian distribution in 100 dimensions. The left image is a projection onto the first two coordinates.”</p></li>
</ul>

<img data-src="figs/tsnerandom.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>t-SNE</h2>
<ul>
<li><p>“For topology, you may need more than one plot”</p></li>
<li><p>“The plots below show two groups of 75 points in 50 dimensional space. Both are sampled from symmetric Gaussian distributions centered at the origin, but one is 50 times more tightly dispersed than the other. The “small” distribution is in effect contained in the large one.”</p></li>
</ul>

<img data-src="figs/tsnetopology.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>Topomap (Doraiswamy et al)</h2>

<img data-src="figs/topomap.jpg" class="r-stretch"><ul>
<li>Topomap preserves the 0-dimensional persistence diagram of the Rips filtration of the high-dimensional data.</li>
</ul>
</section>
<section class="slide level2">
<h2></h2>

<img data-src="figs/understanding-umap.jpg" class="r-stretch"><p>https://pair-code.github.io/understanding-umap/</p>
</section>
<section class="slide level2">
<h2>UMAP</h2>
<ul>
<li>Coenen and Pearce: “UMAP is fast, scaling well in terms of both dataset size and dimensionality. … UMAP can project the 784-dimensional, 70,000-point MNIST dataset in less than 3 minutes, compared to 45 minutes for scikit-learn’s t-SNE implementation. Additionally, UMAP tends to better preserve the global structure of the data.”</li>
</ul>

<img data-src="figs/umapvstsne.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>UMAP</h2>
<ul>
<li>“UMAP, at its core, works very similarly to t-SNE - both use graph layout algorithms to arrange data in low-dimensional space.”</li>
</ul>

<img data-src="figs/umapfuzzygraph.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>UMAP parameters</h2>
<ul>
<li><p><strong>n_neighbors</strong> - the number of approximate nearest neighbors used to construct the initial high-dimensional graph.</p></li>
<li><p><strong>min_dist</strong> - the minimum distance between points in low-dimensional space.</p></li>
</ul>
</section>
<section class="slide level2">
<h2>UMAP parameters</h2>
<ul>
<li><p><strong>n_neighbors</strong> - the number of approximate nearest neighbors used to construct the initial high-dimensional graph.</p></li>
<li><p><strong>min_dist</strong> - the minimum distance between points in low-dimensional space.</p></li>
</ul>

<img data-src="figs/umapmindist-0.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>UMAP parameters</h2>
<ul>
<li><p><strong>n_neighbors</strong> - the number of approximate nearest neighbors used to construct the initial high-dimensional graph.</p></li>
<li><p><strong>min_dist</strong> - the minimum distance between points in low-dimensional space.</p></li>
</ul>

<img data-src="figs/umapmindist-0.8.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>UMAP</h2>
<ul>
<li><p>“However, it’s important to note that, because UMAP and t-SNE both necessarily warp the high-dimensional shape of the data when projecting to lower dimensions, <strong>any given axis or distance in lower dimensions still isn’t directly interpretable in the way of techniques such as PCA.</strong>”</p></li>
<li><p>Suggested reading: https://pair-code.github.io/understanding-umap/supplement.html</p>
<ul>
<li>“Most dimensionality reduction algorithms fit into either one of two broad categories: Matrix factorization (such as PCA) or Graph layout (such as t-SNE).”</li>
<li>“At its core, UMAP is a graph layout algorithm, very similar to t-SNE, but with a number of key theoretical underpinnings that give the algorithm a more solid footing.”</li>
</ul></li>
</ul>
</section>
<section class="slide level2">
<h2>UMAP</h2>

<img data-src="figs/umapvstsne-param.jpg" class="r-stretch"></section>
<section class="slide level2">
<h2>What about user interaction?</h2>

<img data-src="figs/projections.jpg" class="r-stretch"></section></section>
<section>
<section class="title-slide slide level1 center">
<h1>Topological Data Analysis</h1>

</section>
<section class="slide level2">
<h2>What is topology?</h2>
<ul>
<li><p>Topology studies the <em>shape</em> of mathematical objects</p></li>
<li><p>Unlike Geometry, it is not concerned with sizes, angles, nor coordinates</p></li>
<li><p>It is concerned with the <em>connectivity</em> (or lack of) between different “parts” of the object</p></li>
<li><p>Two objects are topologically equivalent if we can transform one into another with continuous transformations (without tearing the object)</p></li>
</ul>

<img data-src="figs/tda_figs/cube-sphere.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>What is topology?</h2>

<img data-src="figs/tda_figs/mug-donnut.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p><a href="https://www.youtube.com/watch?v=9NlqYr6-TpA">Source</a></p>
</div>
</section>
<section class="slide level2">
<h2>Why topology?</h2>
<ul>
<li><p>Since topology analyzes the shape while discarding possibly unnecessary information, it is frequently used for analyzing high-dimensional objects</p></li>
<li><p>Topological data analysis (TDA) uses techniques from topology to analyze datasets</p></li>
<li><p>To do this, it is necessary to construct topological representations of the dataset’s points</p></li>
</ul>
</section>
<section class="slide level2">
<h2>Why topology? - An example in chemistry</h2>

<img data-src="figs/tda_figs/chemistry-1.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Raphaël Tinarrage’s <a href="https://raphaeltinarrage.github.io/files/Slides_SSDS_I.pdf">From Algebraic Topology to Data Analysis</a></p>
</div>
</section>
<section class="slide level2">
<h2>Why topology? - An example in chemistry</h2>

<img data-src="figs/tda_figs/chemistry-2.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Raphaël Tinarrage’s <a href="https://raphaeltinarrage.github.io/files/Slides_SSDS_I.pdf">From Algebraic Topology to Data Analysis</a></p>
</div>
</section>
<section class="slide level2">
<h2>Why topology? - An example in chemistry</h2>

<img data-src="figs/tda_figs/chemistry-3.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Raphaël Tinarrage’s <a href="https://raphaeltinarrage.github.io/files/Slides_SSDS_I.pdf">From Algebraic Topology to Data Analysis</a></p>
</div>
</section>
<section class="slide level2">
<h2>Why topology? - An example in biology</h2>

<img data-src="figs/tda_figs/biology.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Raphaël Tinarrage’s <a href="https://raphaeltinarrage.github.io/files/Slides_SSDS_I.pdf">From Algebraic Topology to Data Analysis</a></p>
</div>
</section>
<section class="slide level2">
<h2>Betti numbers</h2>
<p>The <span class="math inline">\(d^{th}\)</span> Betti number counts the number of <span class="math inline">\(d\)</span>-dimensional holes. It can be used to distinguish between spaces.</p>
<ul>
<li><p><span class="math inline">\(\beta_0(X)\)</span> Connected components in X</p></li>
<li><p><span class="math inline">\(\beta_1(X)\)</span> Tunnels or holes in X</p></li>
<li><p><span class="math inline">\(\beta_2(X)\)</span> Voids in X</p></li>
</ul>

<img data-src="figs/tda_figs/betti-numbers-examples.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>First Example - Map</h2>
<p style="text-align: center;">
What is a peak?
</p>
<p><br>
</p>

<img data-src="figs/tda_figs/example-map-1.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>First Example - Map</h2>
<p style="text-align: center;">
What is a peak?
</p>
<p style="text-align: center;">
First idea: Using local maximum
</p>

<img data-src="figs/tda_figs/example-map-2.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>First Example - Map</h2>
<p style="text-align: center;">
What is a peak?
</p>
<p style="text-align: center;">
Second idea: flooding
</p>

<img data-src="figs/tda_figs/example-map-3.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>First Example - Map</h2>
<p style="text-align: center;">
What is a peak?
</p>
<p style="text-align: center;">
Second idea: flooding
</p>

<img data-src="figs/tda_figs/example-map-4.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>First Example - Map</h2>
<p style="text-align: center;">
What is a peak?
</p>
<p style="text-align: center;">
Second idea: flooding
</p>

<img data-src="figs/tda_figs/example-map-5.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>First Example - Map</h2>
<p style="text-align: center;">
What is a peak?
</p>
<p style="text-align: center;">
Second idea: flooding
</p>

<img data-src="figs/tda_figs/example-map-6.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>First Example - Map</h2>
<p style="text-align: center;">
What is a peak?
</p>
<p style="text-align: center;">
Second idea: flooding
</p>

<img data-src="figs/tda_figs/example-map-7.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>First Example - Map</h2>
<p style="text-align: center;">
What is a peak?
</p>
<p style="text-align: center;">
Second idea: flooding
</p>

<img data-src="figs/tda_figs/example-map-8.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>First Example - Map</h2>
<p style="text-align: center;">
What is a peak?
</p>
<p style="text-align: center;">
Second idea: flooding
</p>

<img data-src="figs/tda_figs/example-map-9.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>First Example - Map</h2>
<p style="text-align: center;">
The island <span class="math inline">\(I\)</span> appears at sea level <span class="math inline">\(b\)</span> (its <strong>birth time</strong>)…
</p>
<p><br>
</p>

<img data-src="figs/tda_figs/example-map-10.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>First Example - Map</h2>
<p style="text-align: center;">
The island <span class="math inline">\(I\)</span> appears at sea level <span class="math inline">\(b\)</span> (its <strong>birth time</strong>)…
</p>
<p style="text-align: center;">
and disapears at seas level <span class="math inline">\(d\)</span> (its <strong>death time</strong>) at local maximum <span class="math inline">\(x\)</span>.
</p>

<img data-src="figs/tda_figs/example-map-11.png" class="quarto-figure quarto-figure-center r-stretch"><p style="text-align: center;">
The point <span class="math inline">\(x\)</span> is a peak if the <strong>persistence</strong><span class="math inline">\(:= d-b\)</span> of the island <span class="math inline">\(I\)</span> is larger than <span class="math inline">\(91\)</span>m (=<span class="math inline">\(300\)</span>ft).
</p>
<div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>First Example - Map</h2>

<img data-src="figs/tda_figs/example-map-persistence.png" class="quarto-figure quarto-figure-center r-stretch"><p>The persistence diagram (PD) of the elevation function is the collection of the points <span class="math inline">\((b,d)\)</span>, where <span class="math inline">\((b,d)\)</span> corresponds to the birth/death of an island.</p>
<div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>First Example - Map</h2>

<img data-src="figs/tda_figs/example-map-persistence-2.png" class="quarto-figure quarto-figure-center r-stretch"><p>The persistence diagram (PD) of the elevation function is the collection of the points <span class="math inline">\((b,d)\)</span>, where <span class="math inline">\((b,d)\)</span> corresponds to the birth/death of an island.</p>
<div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Second Example</h2>

<img data-src="figs/tda_figs/example-persistence-1.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Second Example</h2>

<img data-src="figs/tda_figs/example-persistence-2.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Second Example</h2>

<img data-src="figs/tda_figs/example-persistence-3.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Second Example</h2>

<img data-src="figs/tda_figs/example-persistence-4.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Second Example</h2>

<img data-src="figs/tda_figs/example-persistence-5.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Second Example</h2>

<img data-src="figs/tda_figs/example-persistence-6.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Second Example</h2>

<img data-src="figs/tda_figs/example-persistence-7.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Second Example</h2>

<img data-src="figs/tda_figs/example-persistence-8.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Second Example</h2>

<img data-src="figs/tda_figs/example-persistence-9.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Second Example</h2>

<img data-src="figs/tda_figs/example-persistence-10.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Second Example</h2>

<img data-src="figs/tda_figs/example-persistence-11.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Second Example</h2>

<img data-src="figs/tda_figs/example-persistence-12.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Second Example</h2>

<img data-src="figs/tda_figs/example-persistence-13.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Persistence diagram</h2>

<img data-src="figs/tda_figs/example-persistence-diagram.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Distance between persistence diagrams</h2>
<p><br>
</p>
<p style="text-align: center;">
If we have more than one persistence diagram, how do we measure the distance between them?
</p>

<img data-src="figs/tda_figs/multiple-persistence.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Distance between persistence diagrams</h2>
<p><br>
</p>
<div class="columns">
<div class="column" style="width:30%;">
<p>We place both in the same diagram</p>
</div><div class="column" style="width:70%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/tda_figs/two-persistence-diagrams.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div></div>
<div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Distance between persistence diagrams</h2>
<p><br>
</p>
<div class="columns">
<div class="column" style="width:30%;">
<p>We place both in the same diagram</p>
<p>Get the optimal pair matching between the points (including the diagonal)</p>
</div><div class="column" style="width:70%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/tda_figs/persistence-diagram-matching.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div></div>
<div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Distance between persistence diagrams</h2>
<p><br>
</p>
<div class="columns">
<div class="column" style="width:30%;">
<p>We place both in the same diagram</p>
<p>Get the optimal pair matching between the points (including the diagonal)</p>
<p>The <strong>bottleneck distance</strong> between them will be the largest pair distance</p>
</div><div class="column" style="width:70%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/tda_figs/persistence-diagram-matching.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div></div>
<div class="footer">
<p>Slides based on Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Simplicial complexes</h2>
<p><strong>Definition</strong></p>
<p>We call a non-empty family of sets <span class="math inline">\(K\)</span> with a collection of non-empty subsets <span class="math inline">\(S\)</span> an <em>abstract simplicial complex</em> if:</p>
<ol type="1">
<li><span class="math inline">\(\{v\} \in S\)</span> for all <span class="math inline">\(v \in K\)</span></li>
<li>If <span class="math inline">\(\sigma \in S\)</span> and <span class="math inline">\(\tau \subseteq \sigma\)</span>, then <span class="math inline">\(\tau \in K\)</span>.</li>
</ol>
<p><strong>Terminology</strong></p>
<p>The elements of a simplicial complex <span class="math inline">\(K\)</span> are called <em>simplices</em>. A <span class="math inline">\(k\)</span>-simplex consists of <span class="math inline">\(k+1\)</span> verticies.</p>
<div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Simplicial complexes</h2>
<p><strong>Example</strong></p>
<p>Simplicial complexes can be decomposed into their skeletons, which only contain simplices of a certain dimension.</p>

<img data-src="figs/tda_figs/simplicial-complex-1.png" class="quarto-figure quarto-figure-center r-stretch" style="width:50.0%"><div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Simplicial complexes</h2>
<p><strong>Example</strong></p>
<p>Simplicial complexes can be decomposed into their skeletons, which only contain simplices of a certain dimension.</p>

<img data-src="figs/tda_figs/simplicial-complex-2.png" class="quarto-figure quarto-figure-center r-stretch" style="width:50.0%"><div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Simplicial complexes</h2>
<p><strong>Example</strong></p>
<p>Simplicial complexes can be decomposed into their skeletons, which only contain simplices of a certain dimension.</p>

<img data-src="figs/tda_figs/simplicial-complex-3.png" class="quarto-figure quarto-figure-center r-stretch" style="width:50.0%"><div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Simplicial complexes</h2>
<p><strong>Example</strong></p>
<p>Simplicial complexes can be decomposed into their skeletons, which only contain simplices of a certain dimension.</p>

<img data-src="figs/tda_figs/simplicial-complex-4.png" class="quarto-figure quarto-figure-center r-stretch" style="width:50.0%"><div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Simplicial complexes</h2>
<p><strong>Non-example</strong></p>
<p>This is <em>not</em> a simplicial complex because some higher-dimensional simplices do not intersect in a lower dimensional one!</p>

<img data-src="figs/tda_figs/simplicial-non-example.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Simplicial complexes</h2>
<p><strong>Example</strong></p>

<img data-src="figs/tda_figs/simplicial-complex-abc.png" class="quarto-figure quarto-figure-center r-stretch"><p>Notice that <span class="math inline">\(K\)</span> does not contain the 2-simplex <span class="math inline">\(\{a,b,c\}\)</span></p>
<div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section></section>
<section>
<section class="title-slide slide level1 center">
<h1>From points clouds to simplicial complexes</h1>

</section>
<section class="slide level2">
<h2>From points clouds to simplicial complexes</h2>
<p><br>
</p>

<img data-src="figs/tda_figs/torus-points.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section class="slide level2">
<h2>From points clouds to simplicial complexes</h2>

<img data-src="figs/tda_figs/torus-reconstructed.png" class="quarto-figure quarto-figure-center r-stretch"></section></section>
<section>
<section class="title-slide slide level1 center">
<h1></h1>
<div style="font-size: 180%;">
<p><strong>Strategy 1: Triangulation</strong></p>
</div>
<div style="font-size: 150%;">
<p>Constructing the data’s simplicial complex</p>
</div>
</section>
<section class="slide level2">
<h2>Vietoris-Rips construction</h2>
<p><strong>Definition</strong></p>
<p>Given a set of points <span class="math inline">\(\mathcal{X} = \{x_1,\dots,x_n\}\)</span> and a metric <span class="math inline">\(dist\)</span> (such as the Euclidean distance), pick a threshold <span class="math inline">\(\epsilon\)</span> and build the Vietoris-Rips complex <span class="math inline">\(\mathcal{V}_\epsilon\)</span> defined as:</p>
<p><span class="math display">\[\mathcal{V}_\epsilon := \{\sigma \subseteq \mathcal{X} | \forall u,v \in \sigma : dist(u,v) \leq \epsilon\}\]</span></p>
<p>Equivalently, <span class="math inline">\(\mathcal{V}_\epsilon\)</span> contains all simplices whose <em>diameter</em> is less than or equal to <span class="math inline">\(\epsilon\)</span>.</p>
<div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Vietoris-Rips construction</h2>
<p><strong>Example</strong></p>

<img data-src="figs/tda_figs/vietoris-rips-construction.png" class="quarto-figure quarto-figure-center r-stretch"><p>Draw Euclidean balls (circles) of diameter <span class="math inline">\(\epsilon\)</span> and create a <span class="math inline">\(k\)</span>-simplex <span class="math inline">\(\sigma\)</span> for each subset of <span class="math inline">\(k+1\)</span> points that intersect pairwise.</p>
<div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Some details about this construction</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p><img data-src="figs/tda_figs/vietoris-photo.jpeg"></p>
</div><div class="column" style="width:70%;">
<ul>
<li><p>This construction dates back to a 1927 article by Leopold Vietoris<span class="math inline">\(^1\)</span></p></li>
<li><p>A 2010 paper by Afra Zomorodian<span class="math inline">\(^2\)</span> describes several construction algorithms</p></li>
<li><p>The basic idea is to build higher-dimensional simplices inductively from lower-dimensional ones</p></li>
<li><p>In the worst case, the Vietoris-Rips complex will contain all <span class="math inline">\(2^n\)</span> subsets of its underluing point clous <span class="math inline">\(\mathcal{X}\)</span>!</p></li>
</ul>
</div></div>
<div class="footer">
<div style="font-size: 80%;">
<p><span class="math inline">\(^1\)</span> Vietoris, Leopold. “Über den höheren Zusammenhang kompakter Räume und eine Klasse von zusammenhangstreuen Abbildungen.” Mathematische Annalen 97.1 (1927): 454-472.</p>
<p><span class="math inline">\(^2\)</span> Zomorodian, Afra. “Fast construction of the Vietoris-Rips complex.” Computers &amp; Graphics 34.3 (2010): 263-271.</p>
</div>
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>The betti numbers of a Vietoris-Rips complex</h2>
<p><strong>Example</strong></p>

<img data-src="figs/tda_figs/vietoris-rips-betti.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Issues with this approach</h2>
<p><br>
</p>
<div style="font-size: 120%;">
<ul>
<li><p>How to pick <span class="math inline">\(\epsilon\)</span>?</p></li>
<li><p>There might not be one ‘correct’ value for <span class="math inline">\(\epsilon\)</span>.</p></li>
<li><p>Computationally inefficient</p></li>
</ul>
</div>
<div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Picking <span class="math inline">\(\epsilon\)</span> - Topological Persistence</h2>
<p><strong>Intuition:</strong> Go through all scales and track the topological features</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/tda_figs/persistence-intuition-1.png"></p>
</div></div>
<div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Picking <span class="math inline">\(\epsilon\)</span> - Topological Persistence</h2>
<p><strong>Intuition:</strong> Go through all scales and track the topological features</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/tda_figs/persistence-intuition-2.png"></p>
</div></div>
<div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Picking <span class="math inline">\(\epsilon\)</span> - Topological Persistence</h2>
<p><strong>Intuition:</strong> Go through all scales and track the topological features</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/tda_figs/persistence-intuition-3.png"></p>
</div></div>
<div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Picking <span class="math inline">\(\epsilon\)</span> - Topological Persistence</h2>
<p><strong>Intuition:</strong> Go through all scales and track the topological features</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/tda_figs/persistence-intuition-4.png"></p>
</div></div>
<div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section>
<section class="slide level2">
<h2>Picking <span class="math inline">\(\epsilon\)</span> - Topological Persistence</h2>
<p><strong>Intuition:</strong> Go through all scales and track the topological features</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="figs/tda_figs/persistence-intuition-5.png"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="figs/tda_figs/persistence-intuition-diagram.png"></p>
</div></div>
<div class="footer">
<p>Slides based on Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a></p>
</div>
</section></section>
<section>
<section class="title-slide slide level1 center">
<h1></h1>
<div style="font-size: 180%;">
<p><strong>Strategy 2: Data skeleton</strong></p>
</div>
<div style="font-size: 150%;">
<p>The Mapper Algortihm</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>
<p><br>
</p>
<p>We start in “Math World”, where</p>
<ul>
<li>We draw the data as a smooth manifold</li>
<li>Functions that appear are smooth or continuous</li>
</ul>
<p>We will not need either of these assumptions once we are in the “Data World”.</p>
<p>Even more importantly, data in the real world is <strong>never</strong> like this.</p>
<div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-1.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-2.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-3.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-4.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-5.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-6.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-7.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-8.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-9.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-10.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-11.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-12.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-13.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Math World</h2>

<img data-src="figs/tda_figs/mapper-14.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Why is this useful?</h2>
<p>We get “easy” understanding of the localizations of quantities of interest.</p>

<img data-src="figs/tda_figs/mapper-15.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Why is this useful?</h2>
<p>We get “easy” understanding of the localizations of quantities of interest.</p>

<img data-src="figs/tda_figs/mapper-16.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Why is this useful?</h2>
<p>We get “easy” understanding of the localizations of quantities of interest.</p>

<img data-src="figs/tda_figs/mapper-17.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Why is this useful?</h2>
<p>We get “easy” understanding of the localizations of quantities of interest.</p>

<img data-src="figs/tda_figs/mapper-18.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Why is this useful?</h2>
<p>We get “easy” understanding of the localizations of quantities of interest.</p>

<img data-src="figs/tda_figs/mapper-19.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Why is this useful?</h2>
<p>We get “easy” understanding of the localizations of quantities of interest.</p>

<img data-src="figs/tda_figs/mapper-20.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Why is this useful?</h2>
<p>We get “easy” understanding of the localizations of quantities of interest.</p>

<img data-src="figs/tda_figs/mapper-21.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Why is this useful?</h2>
<p>We get “easy” understanding of the localizations of quantities of interest.</p>
<ul>
<li>Lenses inform us where in the space to look for phenomena.</li>
<li>For easy localizations many different lenses will be informative.</li>
<li>For hard (= geometrically distributed) localizations we have to be more careful. But even then, we frequently get incremental knowledge from a poorly chosen lens.</li>
</ul>
<div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>
<p>We need to adjust the “Math World” view to bring the algorithm into the “Data World”</p>
<ul>
<li>We replace points with open sets in the range of the lens</li>
<li>We replace “connected component of the inverse image” with “clusters in the inverse image”</li>
<li>We connect clusters (nodes) with an edge if they share points in common.</li>
</ul>
<div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>

<img data-src="figs/tda_figs/mapper-22.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>

<img data-src="figs/tda_figs/mapper-23.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>

<img data-src="figs/tda_figs/mapper-24.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>

<img data-src="figs/tda_figs/mapper-25.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>

<img data-src="figs/tda_figs/mapper-26.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>

<img data-src="figs/tda_figs/mapper-27.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>

<img data-src="figs/tda_figs/mapper-28.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>

<img data-src="figs/tda_figs/mapper-29.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>

<img data-src="figs/tda_figs/mapper-30.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>

<img data-src="figs/tda_figs/mapper-31.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>

<img data-src="figs/tda_figs/mapper-32.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>

<img data-src="figs/tda_figs/mapper-33.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section>
<section class="slide level2">
<h2>Data World - Mapper</h2>

<img data-src="figs/tda_figs/mapper-34.png" class="quarto-figure quarto-figure-center r-stretch"><div class="footer">
<p>Slides based on Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p>
</div>
</section></section>
<section>
<section class="title-slide slide level1 center">
<h1>To look further</h1>

</section>
<section class="slide level2">
<h2>References</h2>
<ul>
<li><p>For more information about the persistence diagram, see Vincent Divol’s <a href="https://cds.nyu.edu/data-science-lunch-seminar-series/">CDS Lunch Seminar</a> presentation “Quantifying the topology of datasets using Topological Data Analysis”</p></li>
<li><p>For more information about the mapper algorithm, see Anthony Bak’s <a href="https://www.youtube.com/watch?v=x3Hl85OBuc0">Stanford Seminar - Topological Data Analysis</a> presentation</p></li>
<li><p>To learn more about TDA for Machine Learning, see Bastian Rieck’s <a href="https://bastian.rieck.me/talks/ecml_pkdd_2020/">Topological Data Analysis for Machine Learning</a> tutorial (around 4 hours total)</p></li>
<li><p>For a course in TDA, see Raphaël Tinarrage’s <a href="https://raphaeltinarrage.github.io/EMAp.html">Topological Data Analysis with Persistent Homology</a> summer course</p></li>
</ul>
</section>
<section class="slide level2">
<h2>References</h2>
<p>Some books of interest:</p>
<ul>
<li><p>Edelsbrunner, Herbert, and John L. Harer. Computational topology: an introduction. American Mathematical Society, 2022.</p></li>
<li><p>Dey, Tamal Krishna, and Yusu Wang. Computational topology for data analysis. Cambridge University Press, 2022.</p></li>
<li><p>Carlsson, Gunnar, and Mikael Vejdemo-Johansson. Topological data analysis with applications. Cambridge University Press, 2021.</p></li>
</ul>
<p>Introductory paper:</p>
<ul>
<li>Chazal, Frédéric, and Bertrand Michel. “An introduction to topological data analysis: fundamental and practical aspects for data scientists.” Frontiers in artificial intelligence 4 (2021): 108.</li>
</ul>
</section>
<section class="slide level2">
<h2>References</h2>
<p>TDA in Python:</p>
<ul>
<li>For overall TDA data structures and algorithms: <a href="https://gudhi.inria.fr/">GUDHI</a> (both C++ and Python) or <a href="https://docs.scikit-tda.org/en/latest/">scikit-tda</a></li>
<li>For a faster implementation of the Vietoris-Rips: <a href="https://ripser.scikit-tda.org/en/latest/">Ripser.py</a></li>
<li>For a faster implementation of the Mapper: <a href="https://kepler-mapper.scikit-tda.org/en/latest/">KeplerMapper</a></li>
</ul>
<p>For an open-source library and software collection for topological data analysis and visualization: <a href="https://topology-tool-kit.github.io/">Topology ToolKit</a></p>
<p>For more examples of TDA aplications:</p>
<ul>
<li><a href="https://donut.topology.rocks/">DONUT - Database of Original &amp; Non-Theoretical Uses of Topology</a></li>
<li>Applied Algebraic Topology Research Network <a href="https://www.aatrn.net/seminar">seminar series</a></li>
</ul>
</section>
<section class="slide level2">
<h2>Visualization for NLP</h2>
<ul>
<li>NLP Basic</li>
<li>Visualizing Traditional NLP Model’s Internal Structure</li>
<li>Visualizing Traditional NLP Model’s Behavior</li>
<li>Visualizing LLMs</li>
</ul>
</section>
<section class="slide level2">
<h2>Visualization for NLP</h2>
<ul>
<li>NLP Basic</li>
<li><span style="color: grey;">Visualizing Traditional NLP Model’s Internal Structure</span></li>
<li><span style="color: grey;">Visualizing Traditional NLP Model’s Behavior</span></li>
<li><span style="color: grey;">Visualizing LLMs</span></li>
</ul>
</section>
<section class="slide level2">
<h2>NLP Basic</h2>

<img data-src="./vis4ml_figures/slide1.png" class="r-stretch"></section>
<section class="slide level2">
<h2>NLP Basic</h2>

<img data-src="./vis4ml_figures/slide2.png" class="r-stretch"></section>
<section class="slide level2">
<h2>NLP Basic</h2>

<img data-src="./vis4ml_figures/slide3.png" class="r-stretch"></section>
<section class="slide level2">
<h2>NLP Basic</h2>

<img data-src="./vis4ml_figures/slide4.png" class="r-stretch"></section>
<section class="slide level2">
<h2>NLP Basic</h2>

<img data-src="./vis4ml_figures/slide5.png" class="r-stretch"></section>
<section class="slide level2">
<h2>NLP Basic</h2>

<img data-src="./vis4ml_figures/slide6.png" class="r-stretch"></section>
<section class="slide level2">
<h2>NLP Basic: Tasks</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3>Low-Level Tasks</h3>
<p>Named entity recognition Relation extraction Text classification Keyword extraction Parts-of-speech tagging Grammatical error correction</p>
</div><div class="column" style="width:50%;">
<h3>High-Level Tasks</h3>
<p>Text summarization Text Q&amp;A Text generation Image/video caption Fake news detection Dialogue understanding</p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualization for NLP</h2>
<ul>
<li><span style="color: grey;">NLP Basic</span></li>
<li>Visualizing Traditional NLP Model’s Internal Structure</li>
<li>Visualizing Traditional NLP Model’s Behavior</li>
<li>Visualizing LLMs</li>
</ul>
</section>
<section class="slide level2">
<h2>Visualization for NLP</h2>
<ul>
<li><span style="color: grey;">NLP Basic</span></li>
<li>Visualizing Traditional NLP Model’s Internal Structure</li>
<li><span style="color: grey;">Visualizing Traditional NLP Model’s Behavior</span></li>
<li><span style="color: grey;">Visualizing LLMs</span></li>
</ul>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: RNN</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>RNNbow: Visualizing Learning Via Backpropagation Gradients in RNNs Cashman et al.&nbsp;CGA 2018</p>
</div><div class="column" style="width:50%;">
<p><img data-src="./vis4ml_figures/paper17-1.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: RNN</h2>

<img data-src="./vis4ml_figures/paper17-2.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing Internal Structure: RNN</h2>

<img data-src="./vis4ml_figures/paper17-3.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing Internal Structure: RNN</h2>
<div class="columns">
<div class="column" style="width:45%;">
<p>Comparing gradients at different epochs of training:</p>
</div><div class="column" style="width:55%;">
<p><img data-src="./vis4ml_figures/paper17-4.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: RNN</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Comparing gradients at different epochs of training:</p>
</div><div class="column" style="width:70%;">
<p><img data-src="./vis4ml_figures/paper17-6.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: RNN</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Exploring vanishing gradient</p>
</div><div class="column" style="width:70%;">
<p><img data-src="./vis4ml_figures/paper17-5.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: RNN</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Poorly Learning C</p>
</div><div class="column" style="width:70%;">
<p><img data-src="./vis4ml_figures/paper17-5.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>

<img data-src="./vis4ml_figures/paper13.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Hidden values in LSTM/RNN</p>
</div><div class="column" style="width:70%;">
<p><img data-src="./vis4ml_figures/paper13-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Hidden States Sequence of high-dimensional vectors. What are some options for visualization?</p>
</div><div class="column" style="width:70%;">
<p><img data-src="./vis4ml_figures/paper18-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Hidden States Sequence of high-dimensional vectors. What are some options for visualization?</p>
</div><div class="column" style="width:70%;">
<p><img data-src="./vis4ml_figures/paper18-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Hidden States Sequence of high-dimensional vectors. What are some options for visualization?</p>
</div><div class="column" style="width:70%;">
<p><img data-src="./vis4ml_figures/paper13-5.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>User selects sequences. Configurable threshold: all hidden states in the selected sequence must exceed threshold</p>
</div><div class="column" style="width:70%;">
<p><img data-src="./vis4ml_figures/paper18-3.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>User selects sequences. Configurable threshold: all hidden states in the selected sequence must exceed threshold</p>
</div><div class="column" style="width:70%;">
<p><img data-src="./vis4ml_figures/paper13-6.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Internal Structure: Hidden States</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>How to visualize the collection-level hidden states?</p>
</div><div class="column" style="width:70%;">
<p><img data-src="./vis4ml_figures/paper13-1.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualization for NLP</h2>
<ul>
<li><span style="color: grey;">NLP Basic</span></li>
<li><span style="color: grey;">Visualizing Traditional NLP Model’s Internal Structure</span></li>
<li>Visualizing Traditional NLP Model’s Behavior</li>
<li><span style="color: grey;">Visualizing LLMs</span></li>
</ul>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p><img data-src="./vis4ml_figures/paper19-3.png"> Overall Accuracy on Test Set: 80%</p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>

<img data-src="./vis4ml_figures/paper19-3.png" class="r-stretch"><p>Where does the model make mistakes?</p>
<p>Why does the model make these mistakes?</p>
<p>How can we improve the model performance?</p>
<p>…</p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Subpopulation-Level Error Analysis is Common for NLP Models <img data-src="./vis4ml_figures/paper19-4.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Subpopulation-Level Error Analysis is Common for NLP Models <img data-src="./vis4ml_figures/paper19-4.png"></p>
<p>Not able to capture the errors grounded in specific semantic concepts.</p>
<p>Requires prior knowledge to construct subpopulations.</p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>

<img data-src="./vis4ml_figures/paper19-1.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>

<img data-src="./vis4ml_figures/paper19-5.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Features to Describe A Subpopulation</p>
<ul>
<li>Token
<ul>
<li>e.g., all the documents that contain “delicious”.</li>
</ul></li>
<li>Concept
<ul>
<li>e.g., all the documents that contain “delicious”/“tasty”/”yummy”/…</li>
</ul></li>
<li>High-level Features
<ul>
<li>e.g., all the documents that contain a high percentage of adjectives.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>To describe error-prone subpopulations, we use a set of if-then rules. <img data-src="./vis4ml_figures/paper19-6.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Through iterative design process, we identified four principles of presenting the error rules:</p>
<ul>
<li>Principle 1: Limit the number of conditions.
<ul>
<li>To keep the rule interpretable.</li>
</ul></li>
<li>Principle 2: Test significance.
<ul>
<li>To ensure the high error rate in the subpopulation does not occur by chance</li>
</ul></li>
<li>Principle 3: Limit the cardinality of features.
<ul>
<li>Use low/medium/high instead of actual values (e.g., &gt;20, &lt;30) to keep it interpretable.</li>
</ul></li>
<li>Principle 4: Avoid negation for tokens.
<ul>
<li>To ensure actionable insights.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Automatic Error Discovery <img data-src="./vis4ml_figures/paper19-8.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Automatic Error Discovery <img data-src="./vis4ml_figures/paper19-9.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Automatic Error Discovery <img data-src="./vis4ml_figures/paper19-10.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Views to Support Learning <img data-src="./vis4ml_figures/paper19-7.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Validating <img data-src="./vis4ml_figures/paper19-11.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Validating <img data-src="./vis4ml_figures/paper19-12.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Validating <img data-src="./vis4ml_figures/paper19-13.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Interpret Errors Causes <img data-src="./vis4ml_figures/paper19-14.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Hypothesis Testing <img data-src="./vis4ml_figures/paper19-15.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>
<p>Rule Editing &amp; Concept Construction <img data-src="./vis4ml_figures/paper19-16.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: iSea</h2>

<img data-src="./vis4ml_figures/paper19-2.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing Behavior: Polyjuice</h2>
<div class="columns">
<div class="column" style="width:30%;">
<p>Generating various counterfactuals</p>
</div><div class="column" style="width:70%;">
<p><img data-src="./vis4ml_figures/paper20-1.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing Behavior: Polyjuice</h2>

<img data-src="./vis4ml_figures/paper20-2.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualization for NLP</h2>
<ul>
<li><span style="color: grey;">NLP Basic</span></li>
<li><span style="color: grey;">Visualizing Traditional NLP Model’s Internal Structure</span></li>
<li><span style="color: grey;">Visualizing Traditional NLP Model’s Behavior</span></li>
<li>Visualizing LLMs</li>
</ul>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>

<img data-src="./vis4ml_figures/paper1.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>

<img data-src="./vis4ml_figures/paper2.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:70%;">
<p><img data-src="./vis4ml_figures/paper3-1.png"></p>
</div><div class="column" style="width:30%;">
<p><img data-src="./vis4ml_figures/paper3-2.png"> <img data-src="./vis4ml_figures/paper3-3.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>

<img data-src="./vis4ml_figures/paper4.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>

<img data-src="./vis4ml_figures/paper5.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:40%;">
<p><img data-src="./vis4ml_figures/paper6-1.png"></p>
</div><div class="column" style="width:60%;">
<p><img data-src="./vis4ml_figures/paper6-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="./vis4ml_figures/paper7-1.png"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="./vis4ml_figures/paper7-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>

<img data-src="./vis4ml_figures/paper8.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>

<img data-src="./vis4ml_figures/paper9.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:55%;">
<p><img data-src="./vis4ml_figures/paper10-1.png"></p>
</div><div class="column" style="width:45%;">
<p><img data-src="./vis4ml_figures/paper10-2.png"> <img data-src="./vis4ml_figures/paper10-3.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:35%;">
<p><img data-src="./vis4ml_figures/paper11-1.png"></p>
</div><div class="column" style="width:40%;">
<p><img data-src="./vis4ml_figures/paper11-2.png"></p>
</div><div class="column" style="width:25%;">
<p><img data-src="./vis4ml_figures/paper11-3.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:55%;">
<p><img data-src="./vis4ml_figures/paper12-1.png"></p>
</div><div class="column" style="width:45%;">
<p><img data-src="./vis4ml_figures/paper12-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>

<img data-src="./vis4ml_figures/paper14.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:55%;">
<p><img data-src="./vis4ml_figures/paper15-1.png"></p>
</div><div class="column" style="width:45%;">
<p><img data-src="./vis4ml_figures/paper15-2.png"> <img data-src="./vis4ml_figures/paper15-3.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><img data-src="./vis4ml_figures/paper16-1.png"></p>
</div><div class="column" style="width:55%;">
<p><img data-src="./vis4ml_figures/paper16-2.png"></p>
</div></div>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<p>POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models <img data-src="./vis4ml_figures/paper21-1.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<p>Multi-Modal Interaction <img data-src="./vis4ml_figures/paper21-3.png"></p>
</section>
<section class="slide level2">
<h2>Visualizing LLMs</h2>
<p>POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="./vis4ml_figures/paper21-2.png"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="./vis4ml_figures/paper21-4.png"></p>
</div></div>
</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="figs/vida.jpg" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://engineering.nyu.edu" class="uri">https://engineering.nyu.edu</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="week2-infovis_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="week2-infovis_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="week2-infovis_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="week2-infovis_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="week2-infovis_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="week2-infovis_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="week2-infovis_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="week2-infovis_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="week2-infovis_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="week2-infovis_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'fast',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script>videojs(video_shortcode_videojs_video1);</script>
    

</body></html>